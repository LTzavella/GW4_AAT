---
title: "All previous notes on ICT checks"
output: html_notebook
---


##FILE 1 (OLDER VERSION)

---
title: "Untitled"
author: "Loukia Tzavella"
date: "15/11/2017"
output: html_document
---

* Required packages

```{r}
#Please note that certain packages may not be compatible with your version of R
#R should be updated to the latest version- this script uses R version 3.4.3 (2017-11-30)

required.packages <- c("BayesFactor", "plyr", "here", "data.table", "reshape2", "ggplot2", "viridis", "cowplot")
new.packages <- required.packages[!(required.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)>0) {install.packages(required.packages)}

require(BayesFactor)
require(plyr)
require(here)
require(data.table)
require(reshape2)
require(ggplot2)
require(viridis)
require(cowplot)
```

* Read csv files from the R project sub-folder and add all dataframes to a list

```{r}
files <- list.files(path="~/Library/Mobile Documents/com~apple~CloudDocs/CHAPTER 2/CH2_DATA/all_csvs", all.files = TRUE, full.names = FALSE, no.. = TRUE, pattern = "\\.csv$")

#Delete extension based on the number of characters before ".csv"- all names should have an equal number of characters
names <- substr(files, 1, 6)

#This loop will create a data frame for each .csv file found in your filepath

#might require an alternative for this- loop is too slow for so many data files

all_data <- list() 


for (i in names) {
  filepath <- file.path("~/Library/Mobile Documents/com~apple~CloudDocs/CHAPTER 2/CH2_DATA/all_csvs/", paste(i, ".csv", sep =""))
  all_data[[i]] <- read.csv(filepath, header=T, se="\t")
}
```

Check group numbers
```{r}
group1 <- all_data[sapply(all_data, function(x) all(x$values.current_group == 1))]
group2 <- all_data[sapply(all_data, function(x) all(x$values.current_group == 2))]
group3 <- all_data[sapply(all_data, function(x) all(x$values.current_group == 3))]
```

Check exclusion criteria- i.e. not include in main analyses:

vegan not available- wasn't recorded in raw data- only summary data
```{r}
group1 <- group1[sapply(group1, function(x) any(x$values.psych_disorders==2))]
group1 <- group1[sapply(group1, function(x) any(x$values.psych_drugs=="None"))]
group1 <- group1[sapply(group1, function(x) any(x$values.eating==4))]

group2 <- group2[sapply(group2, function(x) any(x$values.psych_disorders==2))]
group2 <- group2[sapply(group2, function(x) any(x$values.psych_drugs=="None"))]
group2 <- group2[sapply(group2, function(x) any(x$values.eating==4))]

group3 <- group3[sapply(group3, function(x) any(x$values.psych_disorders==2))]
group3 <- group3[sapply(group3, function(x) any(x$values.psych_drugs=="None"))]
group3 <- group3[sapply(group3, function(x) any(x$values.eating==4))]

#It works! -- #DEMOGRAPHICS FILE NOT IN HERE!

veg_include <- unique(demographics$subject[demographics$vegan_criterion_response==2])
psych_include <- unique(demographics$subject[demographics$psych_disorders_criterion_response==2])
drug_include <- unique(demographics$subject[demographics$psych_drugs_criterionoption4_response=="None"])

group1 <- group1[sapply(group1, function (x) any(x$subject %in% veg_include))]
group1 <- group1[sapply(group1, function (x) any(x$subject %in% veg_include))]
group1 <- group1[sapply(group1, function (x) any(x$subject %in% veg_include))]


test <- all_data[sapply(all_data, function(x) any(x$latency[x$values.frame_go==4]==17))]
test2 <- all_data[sapply(all_data, function(x) any(x$latency[x$values.frame_signal==2]==50))]

```
Other exclusions:

Timing-related exclusions:

* Refresh rate is not 60 Hz--> change to duration of each frame- i.e. it has to be 17 ms 
* Trials with stimulus onset times with a delay greater than 150 ms will be removed; 
  
  -75% of signal trials should be valid for each cell of the design (i.e., selection condition x signal-onset distance)- 12 out of 16 trials 
  -75% of trials in each cell of the design for the go test *Important for later analyses* Blocks should be matched- responses for a specific type of trial (e.g., stimulus)
   should be excluded from both blocks
  -Minimum 6 out ot 8 trials for each design cell in the eval task (tastiness and desire to eat ratings considered seperately)


*Very important*
The number of valid trials will be affected by other exclusions as well: 
Missing or inaccurate responses on the CEE task and go test blocks- so the ITI checks should ideally happen after these have been looked at

Performance on the go test is important because we need enough trials for RTs to be analysed- and that refers to correct trials only
For the CEE task, participants might not respond on time (i.e., 'missing' responses)

*Problem?* No exclusions were pre-registered for the number of trials generally needed for the CEE task

*Criteria* After performance exclusions have been made we can proceed to data reductions. 

Performance exclusions for training data: 

* Proportion of correct responses in go trials < 85%
* Proportion of correct responses in stop trials < 65% 
* Proportion of correct responses in stop-change trials < 50% 

* No exclusions for go test performance? 

  Discuss w/ Chris- this was never explicitly declared- the same crtiterion as in go trials (training) could be applied 



> survey$subject <- make.unique(as.character(survey$subject), sep = "_")

> copy <- lapply(copy, function(x) make.unique(as.character(x$subject), sep="_"))

```{r}
training_data <- lapply(all_data, subset, (blockcode=="go_training" | blockcode=="stop_training" | blockcode=="change_training"))
go_test_data <- lapply(all_data, subset, blockcode=="go_test")


group1_train <- lapply(group1, subset, blockcode=="go_training")
group2_train <- lapply(group2, subset, blockcode=="stop_training")
group3_train <- lapply(group3, subset, blockcode=="change_training")

#Recode accuracy values to only have 1s (correct) and 0s (incorrect)

group1_train <- lapply(group1_train, transform, accuracy = ifelse(values.ns_accuracy==1, "1", "0"))

group2_train <- lapply(group2_train, transform, ns_accuracy = ifelse(values.ns_accuracy==1, "1", "0"))
group2_train <- lapply(group2_train, transform, ss_accuracy = ifelse(values.ss_accuracy==1, "1", "0"))

group3_train <- lapply(group3_train, transform, ns_accuracy = ifelse(values.ns_accuracy==1, "1", "0"))
group3_train <- lapply(group3_train, transform, sc_accuracy = ifelse(values.sc_accuracy==1, "1", "0"))

#If values.iti is judged and not only values.trial_ms then we can apply this to the go_test and eval_task data 
group1_train <- lapply(group1_train, transform, iti_check = ifelse(values.iti<800 & values.iti>600, "700", ifelse(values.iti>400 & values.iti<600, "500", "NA")))

group2_train <- lapply(group2_train, transform, iti_check = ifelse(values.iti<800 & values.iti>600, "700", ifelse(values.iti>400 & values.iti<600, "500", "NA")))

group3_train <- lapply(group3_train, transform, iti_check = ifelse(values.iti<800 & values.iti>600, "700", ifelse(values.iti>400 & values.iti<600, "500", "NA")))

#Change accuracy variable structure into integer format 

group1_train <- lapply(group1_train, transform, accuracy = as.numeric(as.character(accuracy)))

group2_train <- lapply(group2_train, transform, ns_accuracy = as.numeric(as.character(ns_accuracy)))
group2_train <- lapply(group2_train, transform, ss_accuracy = as.numeric(as.character(ss_accuracy)))

group3_train <- lapply(group3_train, transform, ns_accuracy = as.numeric(as.character(ns_accuracy)))
group3_train <- lapply(group3_train, transform, sc_accuracy = as.numeric(as.character(sc_accuracy)))


#For participant exclusions we only need to know the 'length' of removed elements from each type of task- see criteria above

###

group1_train_acc <- lapply(group1_train, subset, values.frame_go==112 | values.frame_signal==112)
group1_train_acc  <- lapply(group1_train_acc , droplevels)

group2_train_acc <- lapply(group2_train, subset, values.frame_go==112 | values.frame_signal==112)
group2_train_acc  <- lapply(group2_train_acc , droplevels)

group3_train_acc <- lapply(group3_train, subset, values.frame_go==112 | values.frame_signal==112)
group3_train_acc  <- lapply(group3_train_acc , droplevels)


group1_means <- ldply(group1_train_acc, function(x) goPC= mean(x$accuracy))
group2_means <- ldply(group2_train_acc, function(x) {c(stopPC = mean(x$ss_accuracy[x$values.frame_signal==112]), goPC = mean(x$ns_accuracy[x$values.frame_go==112]))})
group3_means <- ldply(group3_train_acc, function(x) {c(changePC = mean(x$sc_accuracy[x$values.frame_signal==112]), goPC = mean(x$ns_accuracy[x$values.frame_go==112]))})


train_include <- unique(means$.id[means$V1>=0.85])

#This doesn't give us the subject IDs- you can subset the whole element though and select only the names to be included
#e.g., sub001 is the .id name from the accuracy data frame but also the name of the dataframe within the list corresponding to that participant 


test3 <- subset(group1_train, names(group1_train) %in% train_include)



#refactor all variables
```

##FILE 2

---
title: "Training analyses"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

* Clear the environment 
```{r}
rm(list=ls())
```


* Load all functions from supporting script
```{r}
source("Analysis_functions.R")
```

* Read csv files from the specified directory and create dataframes for all files 
```{r}
#Input your directory in the path- csv files required
files <- list.files(path="C:/Users/lucia/iCloudDrive/Desktop/CHAPTER 2/CH2_DATA/Inquisit_data/new/", all.files = TRUE, full.names = FALSE, no.. = TRUE, pattern = ".*csv")

#Delete extension based on the number of characters before ".csv"- all names should have an equal number of characters
names <- substr(files, 1, 6)

#This loop will create a data frame for each .csv file found in your filepath
for (i in names) {
  filepath <- file.path("C:/Users/lucia/iCloudDrive/Desktop/CHAPTER 2/CH2_DATA/Inquisit_data/new/", paste(i, ".csv", sep =""))
  assign(i, read.csv(filepath, header=TRUE, sep="\t"))
}
```

* Combine dataframes into one for pre-processing
```{r}
#Create a list for all data frames 
dfs <- Filter(function(x) is(x, "data.frame"), mget(ls()))


#Combine all data frames (by row)
all_data <- do.call(rbind, dfs)
```

* Transform unique participant codes into numerical IDs 
```{r}
all_data <- transform(all_data, script.subjectid=as.numeric(factor(script.subjectid)))
all_data$script.subjectid <- as.factor(all_data$script.subjectid)
```

* Change the structure of selected variables and rename them

```{r}
#Change structure of the x coordinates and RT measures:

all_data$values.total_rt <- as.numeric(all_data$values.total_rt)
all_data$values.init_time <- as.numeric(all_data$values.init_time)
all_data$values.mousex <- as.numeric(all_data$values.mousex)
  
#Change structure of categorical variables:

all_data$blockcode <- as.factor(all_data$blockcode)
all_data$trialcode <- as.factor(all_data$trialcode)
all_data$values.eval_jpg <- as.factor(all_data$values.eval_jpg)
all_data$values.eval_selection <- as.factor(all_data$values.eval_selection)
all_data$values.eval_novelty <- as.factor(all_data$values.eval_novelty)
all_data$values.eval_healthiness <- as.factor(all_data$values.eval_healthiness)
  
#Rename variables and their levels:

names(all_data)[1] <- ""
names(all_data)[] <- ""

levels(all_data$values.eval_selection)[levels(all_data$values.eval_selection)=="1"] <- "Selected"
levels(all_data$values.eval_selection)[levels(all_data$values.eval_selection)=="2"] <- "Non_selected"
levels(all_data$values.eval_novelty)[levels(all_data$values.eval_novelty)=="1"] <- "Old"
levels(all_data$values.eval_novelty)[levels(all_data$values.eval_novelty)=="2"] <- "Novel"
levels(all_data$values.eval_healthiness)[levels(all_data$values.eval_healthiness)=="1"] <- "Healthy"
levels(all_data$values.eval_healthiness)[levels(all_data$values.eval_healthiness)=="2"] <- "Unhealthy"

#Refactor variables after subsetting
all_data$blockcode <- factor(all_data$blockcode)
all_data$trialcode <- factor(all_data$trialcode)
all_data$values.eval_jpg <- factor(all_data$values.eval_jpg)
all_data$values.eval_selection <- factor(all_data$values.eval_selection)
all_data$values.eval_novelty <- factor(all_data$values.eval_novelty)
all_data$values.eval_healthiness <- factor(all_data$values.eval_healthiness)
all_data$values.current_group <- factor(all_data$values.current_group)
```


## Main outcomes for training analyses ["eet_data"]

* Subset the data so only the samples where a response was made are kept for pre-processing. 
```{r}
eet_data<- subset(all_data, all_data$values.marker==2)
```

Each EET block consists of 36 trials, from which the fist four should be excluded. These are 'dummy' trials introduced as practice trials. 
```{r}
eet_data <- subset(eet_data, eet_data$values.dummy_trial==2) #This will change later maybe to be according to trialnumbers
```


* Coordinate log transformation for EET responses with conditional logic for counterbalancing- side of EET positive & negative anchors
* Apply function to subsetted dataframe with completed EET trials. 
```{r}
eet_data <- transform_x(eet_data$expressions.min_eval, eet_data$expressions.max_eval, eet_data$values.mousex, eet_data)

write.table(eet_data, file="eet_data.csv", row.names = FALSE)

```

```{r}
plot(eet_data$newx[[eet_data$values.eval_healthiness==2]])

mean_data <- aggregate(newx ~ values.eval_healthiness * values.eval_selection * values.eval_novelty* values.current_group, data=eet_data, mean)
write.table(mean_data, file="mean_data.csv", row.names = FALSE)

```

```{r}
pew <- anovaBF(data=eet_data, newx ~ values.eval_healthiness * values.current_group * values.eval_selection)

summary(pew)

```

* Get goRTs- time when participants have reached the target and have stopped the mouse for more than 3 samples
Note: First sample out of the three is used as the timepoint for the goRT registration
```{r}

all_data$lag_rt <- shift(all_data$values.total_rt, 3)

all_data$goRT <- ifelse(all_data$values.stopping==1 & all_data$values.nomovement==3 & all_data$values.target_reached==1, all_data$lag_rt, "0")

```

```{r}
go_test <- subset(all_data, blockcode=="go_test" & goRT >0)

```

Analysis of the go_tests will happen with the subsetted data frames where goRT>0 only get those trials (this also means the response was correct-no errors included)- to analyse both we need to look at nontarget_reached values or use accuracy if rts are not of interest

*Need to do all this with the SSRTs, CSRTs, and change point etc. 


---
title: "ICT_preliminary"
author: "Loukia Tzavella"
date: "02/01/2018"
output: html_document
---

* Load data files
```{r}
#Save names of all csv files from project subdirectory

files <- list.files(here("all_csvs"), all.files = TRUE, full.names = FALSE, no.. = TRUE, pattern = "\\csv$")

#Read all csv files into a list of dataframes 

data <- lapply(here("all_csvs", files), function(x) {fread(x)})

data <- lapply(data, function(x) as.data.frame(x))
```

* Apply participant-level exclusions for pre-registered analyses

    + Past and/or current diagnosis of psychiatric and/or neurological disorder(s)
    + Past and/or current history of drug and/or alcohol abuse
    + Vegan or vegetarian dietary preferences
    + Past and/or current diagnosis of binge eating disorder

    + Refresh frames are not equal to 17 milliseconds (ms)

```{r}
#Load csv file with all survey data. Note that N differs as all responses have been recorded (incomplete, crashes etc.).

survey <- read.csv(here("demographics.csv"), header=T)

#Make unique IDs to deal with subject ID duplicates created during lab testing

survey$unique_ID = paste(survey$subject, survey$time)

data <- lapply(data, function(x) cbind(x, unique_ID = paste(x$subject, x$script.starttime)))

#Assign names to the list elements (subject IDs) in case exclusions need to be checked manually

subs <- lapply(data, function(x) head(x$unique_ID, n=1))
subs <- lapply(subs, function(x) as.character(x))
names(data) <- subs

#Obtain subject IDs for eligible participants [keep lists with IDs for potential exploratory analyses]

veg_IDs <- unique(survey$unique_ID[survey$vegan_criterion_response==2])
psych_IDs <- unique(survey$unique_ID[survey$psych_disorders_criterion_response==2])
drug_IDs <- unique(survey$unique_ID[survey$psych_drugs_criterionoption4_response=="None"])

#Select data files from eligible participants into a new list called 'main'
#Eating disorders were recorded as part of the eligibility survey so data can be found in the main data files only

main <- data[sapply(data, function (x) any(x$unique_ID %in% veg_IDs))]
main <- main[sapply(main, function (x) any(x$unique_ID %in% psych_IDs))]
main <- main[sapply(main, function (x) any(x$unique_ID %in% drug_IDs))]

main <- main[sapply(main, function(x) any(x$values.eating==4))]

#Select data files with correct refresh frames (the 4th frame is random- anything after the 2nd frame is acceptable)

main <- main[sapply(main, function(x) any(x$latency[x$values.frame_go==4]==17))]

#Add a new column to the data for ITI durations

main <- lapply(main, transform, iti_check = ifelse(values.iti<=850 & values.iti>600, "700", ifelse(values.iti>400 & values.iti<600, "500", "NA")))
```

Other exclusions:

Timing-related exclusions:

* Trials with stimulus onset times with a delay greater than 150 ms will be removed; 
  
  -75% of signal trials should be valid for each cell of the design (i.e., selection condition x signal-onset distance)- 12 out of 16 trials 
  -75% of trials in each cell of the design for the go test *Important for later analyses* Blocks should be matched- responses for a specific type of trial (e.g., stimulus) should be excluded from both blocks
  -Minimum 6 out ot 8 trials for each design cell in the eval task (tastiness and desire to eat ratings considered seperately)


*Very important*
The number of valid trials will be affected by other exclusions as well: 
Missing or inaccurate responses on the CEE task and go test blocks- so the ITI checks should ideally happen after these have been looked at

Performance on the go test is important because we need enough trials for RTs to be analysed- and that refers to correct trials only
For the CEE task, participants might not respond on time (i.e., 'missing' responses)


Performance exclusions for training data: 

* Proportion of correct responses in go trials < 85%
* Proportion of correct responses in stop trials < 65% 
* Proportion of correct responses in stop-change trials < 50% 

```{r}
#Recode accuracy values to only have 1s (correct) and 0s (incorrect)

main <- lapply(main, transform, accuracy = ifelse(values.ns_accuracy==1 & (blockcode=="go_training"|blockcode=="go_test"|blockcode=="go_test_end"), "1",
        ifelse(values.ns_accuracy==1 & (blockcode=="stop_training"|blockcode=="change_training") & values.frame_go==112, "1", 
        ifelse(values.ss_accuracy==1 & blockcode=="stop_training" & values.frame_signal==112, "1", 
        ifelse(values.sc_accuracy==1 & blockcode=="change_training" & values.frame_signal==112, "1", "0")))))

#Change accuracy variable structure into numeric format 

main <- lapply(main, transform, accuracy = as.numeric(as.character(accuracy)))

#Split data by group

group1 <- main[sapply(main, function(x) all(x$values.current_group == 1))]
group2 <- main[sapply(main, function(x) all(x$values.current_group == 2))]
group3 <- main[sapply(main, function(x) all(x$values.current_group == 3))]

#GTR:   Proportion of correct go (no-signal) trials in the training blocks
#GPR:   Proportion of correct go (no-signal) trials in the pre-training go-test blocks [not used for exclusions]
#GPO:   Proportion of correct go (no-signal) trials in the post-training go-test blocks [not used for exclusions]
#SS:    Proportion of sucessful stops in training (signal trials) 
#CS:    Proportion of successful changes in training (signal trials)

group1_means <- ldply(group1, function(x) {c(GTR = mean(x$accuracy[(x$values.frame_go==112|x$values.frame_signal==112) & x$blockcode=="go_training"]), 
                                             GPR = mean(x$accuracy[x$values.frame_go==112 & x$blockcode=="go_test"]), 
                                             GPO = mean(x$accuracy[x$values.frame_go==112 & x$blockcode=="go_test_end"]))})

group2_means <- ldply(group2, function(x) {c(GTR = mean(x$accuracy[x$values.frame_go==112 & x$blockcode=="stop_training"]), 
                                             GPR = mean(x$accuracy[x$values.frame_go==112 & x$blockcode=="go_test"]), 
                                             GPO = mean(x$accuracy[x$values.frame_go==112 & x$blockcode=="go_test_end"]),
                                             SS = mean(x$accuracy[x$values.frame_signal==112 & x$blockcode=="stop_training"]))})

group3_means <- ldply(group3, function(x) {c(GTR = mean(x$accuracy[x$values.frame_go==112 & x$blockcode=="change_training"]), 
                                             GPR = mean(x$accuracy[x$values.frame_go==112 & x$blockcode=="go_test"]), 
                                             GPO = mean(x$accuracy[x$values.frame_go==112 & x$blockcode=="go_test_end"]),
                                             CS = mean(x$accuracy[x$values.frame_signal==112 & x$blockcode=="change_training"]))})

#Obtain IDs for eligible participants in each group

IDs <- c(unique(group1_means$.id[group1_means$GTR>=0.85]),unique(group2_means$.id[group2_means$GTR>=0.85 & group2_means$SS >=0.65]),unique(group3_means$.id[group3_means$GTR>=0.85 & group3_means$CS >=0.50]))

main <- main[sapply(main, function (x) any(x$unique_ID %in% IDs))]

#Create data frames for tastiness and desire to eat ratings (complete responses only)

tas <- ldply(main, subset, (blockcode=="tastiness" & values.marker==2))
des <- ldply(main, subset, (blockcode=="desiretoeat" & values.marker==2))

#Run function for removing duplicate items 
rm_d <- function(data) {
  x <- unique(data[duplicated(data$values.eval_jpg), ])
  r <- as.numeric(rownames(x))
  data <- subset(data, !(rownames(data) %in% r))
  return(data)
}

#Apply function to the two datasets
tas <- gapply(tas, FUN = rm_d, groups=tas$unique_ID)
des <- gapply(des, FUN = rm_d, groups=des$unique_ID)
```

```{r}

#ITIs will be checked for go-test blocks (pre and post) as well as training blocks
#In case of NA values, data will be checked further according to the proportions of NAs in specific design cells:

#SE:    Selected condition, early signal-onset distance [training]
#SM:    Selected condition, mid signal-onset distance [training]
#NE:    Non-selected condition, early signal-onset distance [training]
#NM:    Non-selected condition, mid signal-onset distance [training]
#SH1:   Selected condition, healthy category, pre-training [go test]
#SU1:   Selected condition, unhealthy category, pre-training [go test]
#NH1:   Non-selected condition, healthy category, pre-training [go test]
#NU1:   Non-selected condition, unhealthy category, pre-training [go test]
#SH2:   Selected condition, healthy category, post-training [go test]
#SU2:   Selected condition, unhealthy category, post-training [go test]
#NH2:   Non-selected condition, healthy category, post-training [go test]
#NU2:   Non-selected condition, unhealthy category, post-training [go test]

#iti_checks1 <- ldply(group1, function(x) {cbind(table(x$iti_check[x$values.frame_signal==112 & x$blockcode=="go_training"]), 
                                          #table(x$iti_check[x$values.frame_go==112 & x$blockcode=="go_test"]), 
                                          #table(x$iti_check[x$values.frame_go==112 & x$blockcode=="go_test_end"]),
                                          #table(x$iti_check[x$values.frame_go==4 & x$blockcode=="tastiness" & x$values.trialnumber>4]),
                                          #table(x$iti_check[x$values.frame_go==4 & x$blockcode=="desiretoeat" & x$values.trialnumber>4]))})

#iti_checks1 <- iti_checks1[seq(3, nrow(iti_checks1), 3), ]

#iti_checks2 <- ldply(group2, function(x) {cbind(table(x$iti_check[x$values.frame_signal==112 & x$blockcode=="stop_training"]), 
                                          #table(x$iti_check[x$values.frame_go==112 & x$blockcode=="go_test"]), 
                                          #table(x$iti_check[x$values.frame_go==112 & x$blockcode=="go_test_end"]),
                                          #table(x$iti_check[x$values.frame_go==4 & x$blockcode=="tastiness" & x$values.trialnumber>4]),
                                          #table(x$iti_check[x$values.frame_go==4 & x$blockcode=="desiretoeat" & x$values.trialnumber>4]))})


#iti_checks3 <- ldply(group3, function(x) {cbind(table(x$iti_check[x$values.frame_signal==112 & x$blockcode=="change_training"]), 
                                          #table(x$iti_check[x$values.frame_go==112 & x$blockcode=="go_test"]), 
                                          #table(x$iti_check[x$values.frame_go==112 & x$blockcode=="go_test_end"]),
                                          #table(x$iti_check[x$values.frame_go==4 & x$blockcode=="tastiness" & x$values.trialnumber>4]),
                                          #table(x$iti_check[x$values.frame_go==4 & x$blockcode=="desiretoeat" & x$values.trialnumber>4]))})

#iti_checks <- ldply(group1, function(x) table(x$iti_check[x$values.frame_go==112 & x$blockcode=="go_training"])) 
#iti_checks <- ldply(group1, function(x) table(x$iti_check[x$values.frame_go==112 & x$blockcode=="go_test"])) 
#iti_checks <- ldply(group1, function(x) table(x$iti_check[x$values.frame_go==112 & x$blockcode=="go_test_end"])) 


#iti_checks <- ldply(group2, function(x) table(x$iti_check[x$values.frame_go==112 & x$blockcode=="stop_training"])) 
#iti_checks <- ldply(group2, function(x) table(x$iti_check[x$values.frame_go==112 & x$blockcode=="go_test"])) 
#iti_checks <- ldply(group2, function(x) table(x$iti_check[x$values.frame_go==112 & x$blockcode=="go_test_end"])) 

#findFirst <- function(data, jpg, position) {
#  x <- which(data == jpg)
#  if (position == 1) out <- x[1]
#  else out <- x[which(diff(x) != 1)[position-1] + 1]
#  out
#}

#invec is the input vector.
#value is the value you're looking for.
#event is the position (for example, first, second, third sequence).
#Usage would be:


#findFirst(ex, "242", 2) 


#hchecks<- ldply(group3, function(x) {table(x$values.eval_healthiness[x$values.frame_go==4 & x$blockcode=="desiretoeat" & x$values.trialnumber>4])})

#hre <- subset(hchecks, hchecks$`1`==16 | hchecks$`2`==16)
```

*Proceed to analysis and check again later on what to do


```{r}

#Coordinate log transformation for EET responses with conditional logic for counterbalancing- side of EET positive & negative anchors
#Apply function to subsetted dataframe with completed trials

transform_x <- function(min, max, mousex, data)
{newx <- (mousex - min)/(max-min)
newx <- newx * 100
if (2 %in% data$values.eval_side) {newx <- abs(newx - 100)}
newdata <- as.data.frame(cbind(data, newx))
newx <- as.numeric(newdata$newx)
return(newdata)
}

#Apply transform function to both lists 

tas <- lapply(tas, function(x) {transform_x(x$expressions.min_eval, x$expressions.max_eval, x$values.markerx, data=x)})
des <- lapply(des, function(x) {transform_x(x$expressions.min_eval, x$expressions.max_eval, x$values.markerx, data=x)})


#Change the names and structure of variables to be included in later analyses

tas <- lapply(tas, transform, healthiness = as.factor(values.eval_healthiness))
tas <- lapply(tas, transform, novelty = as.factor(values.eval_novelty))
tas <- lapply(tas, transform, selection = as.factor(values.eval_selection))
tas <- lapply(tas, transform, item = as.factor(values.eval_jpg))


des <- lapply(des, transform, healthiness = as.factor(values.eval_healthiness))
des <- lapply(des, transform, novelty = as.factor(values.eval_novelty))
des <- lapply(des, transform, selection = as.factor(values.eval_selection))
des <- lapply(des, transform, item = as.factor(values.eval_jpg))


#eet_means <- ldply(eet_data, function(x) {c(group=mean(x$values.current_group), 
                                            #HSO= mean(x$newx[x$healthiness==1 & x$selection==1 & x$novelty==1]), 
                                            #HSN= mean(x$newx[x$healthiness==1 & x$selection==1 & x$novelty==2]),
                                            #HNO= mean(x$newx[x$healthiness==1 & x$selection==2 & x$novelty==1]),
                                            #HNN= mean(x$newx[x$healthiness==1 & x$selection==2 & x$novelty==2]),
                                            #USO= mean(x$newx[x$healthiness==2 & x$selection==1 & x$novelty==1]),
                                            #USN= mean(x$newx[x$healthiness==2 & x$selection==1 & x$novelty==2]),
                                            #UNO= mean(x$newx[x$healthiness==2 & x$selection==2 & x$novelty==1]),
                                            #UNN= mean(x$newx[x$healthiness==2 & x$selection==2 & x$novelty==2]))})

#write.csv(eet_means, file="means.csv", row.names = FALSE)
```

* Bayesian analyses

** H1.  Compared to go training (control), both stop and stop-change training tasks will reduce positive evaluations of unhealthy foods.

    + Stop-change training will lead to a greater decrease in ratings of tastiness and desire to eat for unhealthy foods than stop training, relative       to the go group. 

    + The expected differences in the evaluations of foods will be greater for desire to eat than tastiness ratings.
    
```{r}
#Convert lists into dataframes 

tas <- ldply(tas, as.data.frame)
des <- ldply(des, as.data.frame)

#Make datasets for healthy and unhealthy food trials

tas_h <- subset(tas, healthiness==1)
tas_u <- subset(tas, healthiness==2)
des_h <- subset(des, healthiness==1)
des_u <- subset(des, healthiness==2)

#Analyses for H1   

#Tastiness ratings - unhealthy foods
tas_u1 <- lmBF(data=tas_u, newx ~ values.current_group * selection * novelty + item + unique_ID, whichRandom = c("item", "unique_ID"))
tas_u2 <- lmBF(data=tas_u, newx ~ values.current_group * selection + item + unique_ID, whichRandom = c("item", "unique_ID"))
tas_u3 <- lmBF(data=tas_u, newx ~ values.current_group * novelty + item + unique_ID, whichRandom = c("item", "unique_ID"))
tas_u4 <- lmBF(data=tas_u, newx ~ values.current_group + novelty * selection + item + unique_ID, whichRandom = c("item", "unique_ID"))
tas_u5 <- lmBF(data=tas_u, newx ~ values.current_group * novelty + selection + item + unique_ID, whichRandom = c("item", "unique_ID"))
tas_u6 <- lmBF(data=tas_u, newx ~ values.current_group * selection + novelty + item + unique_ID, whichRandom = c("item", "unique_ID"))
tas_u7 <- lmBF(data=tas_u, newx ~ values.current_group + selection + novelty + item + unique_ID, whichRandom = c("item", "unique_ID"))
tas_u8 <- lmBF(data=tas_u, newx ~ values.current_group + selection + item + unique_ID, whichRandom = c("item", "unique_ID"))
tas_u9 <- lmBF(data=tas_u, newx ~ values.current_group + novelty + item + unique_ID, whichRandom = c("item", "unique_ID"))
tas_u10 <- lmBF(data=tas_u, newx ~ values.current_group + item + unique_ID, whichRandom = c("item", "unique_ID"))

lm1 <- glmer(data=tas_u, newx ~ values.current_group * selection + (1|item) + (1|unique_ID))

#Get ouput for all 'tas_u' models
tas_u_all <- c(tas_u1, tas_u2, tas_u3, tas_u4, tas_u5, tas_u6, tas_u7, tas_u8, tas_u9, tas_u10)
tas_u_all

#Bayesian t-tests
tas_ut1 <- ttestBF(tas_u$newx[tas_u$values.current_group==3], tas_u$newx[tas_u$values.current_group==1], paired=FALSE, nullInterval = c(-Inf, 0))

tas_ut2 <- ttestBF(tas_u$newx[tas_u$values.current_group==2], tas_u$newx[tas_u$values.current_group==1], paired=FALSE, nullInterval = c(-Inf, 0))

tas_ut3 <- ttestBF(tas_u$newx[tas_u$values.current_group==3 & tas_u$selection==1], tas_u$newx[tas_u$values.current_group==1 & tas_u$selection==1], paired=FALSE, nullInterval = c(-Inf, 0))

tas_ut4 <- ttestBF(tas_u$newx[tas_u$values.current_group==3 & tas_u$selection==2], tas_u$newx[tas_u$values.current_group==1 & tas_u$selection==2], paired=FALSE, nullInterval = c(-Inf, 0))

tas_ut5 <- ttestBF(tas_u$newx[tas_u$values.current_group==3 & tas_u$selection==1 & tas_u$novelty==1], tas_u$newx[tas_u$values.current_group==1 & tas_u$selection==1 & tas_u$novelty==1], paired=FALSE, nullInterval = c(-Inf, 0))

tas_ut6 <- ttestBF(tas_u$newx[tas_u$values.current_group==3 & tas_u$selection==1 & tas_u$novelty==2], tas_u$newx[tas_u$values.current_group==1 & tas_u$selection==1 & tas_u$novelty==2], paired=FALSE, nullInterval = c(-Inf, 0))

tas_ut7 <- ttestBF(tas_u$newx[tas_u$values.current_group==3 & tas_u$selection==2 & tas_u$novelty==1], tas_u$newx[tas_u$values.current_group==1 & tas_u$selection==2 & tas_u$novelty==1], paired=FALSE, nullInterval = c(-Inf, 0))

tas_ut8 <- ttestBF(tas_u$newx[tas_u$values.current_group==3 & tas_u$selection==2 & tas_u$novelty==2], tas_u$newx[tas_u$values.current_group==1 & tas_u$selection==2 & tas_u$novelty==2], paired=FALSE, nullInterval = c(-Inf, 0))
#####

classical.test = t.test(tas_u$newx[tas_u$values.current_group==3 & tas_u$selection==1 & tas_u$novelty==2], tas_u$newx[tas_u$values.current_group==1 & tas_u$selection==1 & tas_u$novelty==2], data = tas_u, var.eq = TRUE)

classical.test

#Check evidence for the null (example)

1/tas_ut2[1]

#Desire to eat ratings - unhealthy foods
des_u1 <- lmBF(data=des_u, newx ~ values.current_group * selection * novelty + item + unique_ID, whichRandom = c("item", "unique_ID"))
des_u2 <- lmBF(data=des_u, newx ~ values.current_group * selection + item + unique_ID, whichRandom = c("item", "unique_ID"))
des_u3 <- lmBF(data=des_u, newx ~ values.current_group * novelty + item + unique_ID, whichRandom = c("item", "unique_ID"))
des_u4 <- lmBF(data=des_u, newx ~ values.current_group + novelty * selection + item + unique_ID, whichRandom = c("item", "unique_ID"))
des_u5 <- lmBF(data=des_u, newx ~ values.current_group * novelty + selection + item + unique_ID, whichRandom = c("item", "unique_ID"))
des_u6 <- lmBF(data=des_u, newx ~ values.current_group * selection + novelty + item + unique_ID, whichRandom = c("item", "unique_ID"))
des_u7 <- lmBF(data=des_u, newx ~ values.current_group + selection + novelty + item + unique_ID, whichRandom = c("item", "unique_ID"))
des_u8 <- lmBF(data=des_u, newx ~ values.current_group + selection + item + unique_ID, whichRandom = c("item", "unique_ID"))
des_u9 <- lmBF(data=des_u, newx ~ values.current_group + novelty + item + unique_ID, whichRandom = c("item", "unique_ID"))
des_u10 <- lmBF(data=des_u, newx ~ values.current_group + item + unique_ID, whichRandom = c("item", "unique_ID"))

#Get ouput for all 'des_u' models
des_u_all <- c(des_u1, des_u2, des_u3, des_u4, des_u5, des_u6, des_u7, des_u8, des_u9, des_u10)
des_u_all

#Bayesian t-tests
des_ut1 <- ttestBF(des_u$newx[des_u$values.current_group==3], des_u$newx[des_u$values.current_group==1], paired=FALSE, nullInterval = c(-Inf, 0))

des_ut2 <- ttestBF(des_u$newx[des_u$values.current_group==2], des_u$newx[des_u$values.current_group==1], paired=FALSE, nullInterval = c(-Inf, 0))

des_ut3 <- ttestBF(des_u$newx[des_u$values.current_group==3 & des_u$selection==1], des_u$newx[des_u$values.current_group==1 & des_u$selection==1], paired=FALSE, nullInterval = c(-Inf, 0))

des_ut4 <- ttestBF(des_u$newx[des_u$values.current_group==3 & des_u$selection==2], des_u$newx[des_u$values.current_group==1 & des_u$selection==2], paired=FALSE, nullInterval = c(-Inf, 0))

des_ut5 <- ttestBF(des_u$newx[des_u$values.current_group==3 & des_u$selection==1 & des_u$novelty==1], des_u$newx[des_u$values.current_group==1 & des_u$selection==1 & des_u$novelty==1], paired=FALSE, nullInterval = c(-Inf, 0))

des_ut6 <- ttestBF(des_u$newx[des_u$values.current_group==3 & des_u$selection==1 & des_u$novelty==2], des_u$newx[des_u$values.current_group==1 & des_u$selection==1 & des_u$novelty==2], paired=FALSE, nullInterval = c(-Inf, 0))

des_ut7 <- ttestBF(des_u$newx[des_u$values.current_group==3 & des_u$selection==2 & des_u$novelty==1], des_u$newx[des_u$values.current_group==1 & des_u$selection==2 & des_u$novelty==1], paired=FALSE, nullInterval = c(-Inf, 0))

des_ut8 <- ttestBF(des_u$newx[des_u$values.current_group==3 & des_u$selection==2 & des_u$novelty==2], des_u$newx[des_u$values.current_group==1 & des_u$selection==2 & des_u$novelty==2], paired=FALSE, nullInterval = c(-Inf, 0))

#Tastiness ratings - healthy foods
tas_h1 <- lmBF(data=tas_h, newx ~ values.current_group * selection * novelty + item + unique_ID, whichRandom = c("item", "unique_ID"))
tas_h2 <- lmBF(data=tas_h, newx ~ values.current_group * selection + item + unique_ID, whichRandom = c("item", "unique_ID"))
tas_h3 <- lmBF(data=tas_h, newx ~ values.current_group * novelty + item + unique_ID, whichRandom = c("item", "unique_ID"))
tas_h4 <- lmBF(data=tas_h, newx ~ values.current_group + novelty * selection + item + unique_ID, whichRandom = c("item", "unique_ID"))
tas_h5 <- lmBF(data=tas_h, newx ~ values.current_group * novelty + selection + item + unique_ID, whichRandom = c("item", "unique_ID"))
tas_h6 <- lmBF(data=tas_h, newx ~ values.current_group * selection + novelty + item + unique_ID, whichRandom = c("item", "unique_ID"))
tas_h7 <- lmBF(data=tas_h, newx ~ values.current_group + selection + novelty + item + unique_ID, whichRandom = c("item", "unique_ID"))
tas_h8 <- lmBF(data=tas_h, newx ~ values.current_group + selection + item + unique_ID, whichRandom = c("item", "unique_ID"))
tas_h9 <- lmBF(data=tas_h, newx ~ values.current_group + novelty + item + unique_ID, whichRandom = c("item", "unique_ID"))
tas_h10 <- lmBF(data=tas_h, newx ~ values.current_group + item + unique_ID, whichRandom = c("item", "unique_ID"))

#Get ouput for all models
tas_h_all <- c(tas_h1, tas_h2, tas_h3, tas_h4, tas_h5, tas_h6, tas_h7, tas_h8, tas_h9, tas_h10)
tas_h_all

#Bayesian t-tests
tas_ht1 <- ttestBF(tas_h$newx[tas_h$values.current_group==3], tas_h$newx[tas_h$values.current_group==1], paired=FALSE, nullInterval = c(-Inf, 0))

tas_ht2 <- ttestBF(tas_h$newx[tas_h$values.current_group==2], tas_h$newx[tas_h$values.current_group==1], paired=FALSE, nullInterval = c(-Inf, 0))

tas_ht3 <- ttestBF(tas_h$newx[tas_h$values.current_group==3 & tas_h$selection==1], tas_h$newx[tas_h$values.current_group==1 & tas_h$selection==1], paired=FALSE, nullInterval = c(-Inf, 0))

tas_ht4 <- ttestBF(tas_h$newx[tas_h$values.current_group==3 & tas_h$selection==2], tas_h$newx[tas_h$values.current_group==1 & tas_h$selection==2], paired=FALSE, nullInterval = c(-Inf, 0))

tas_ht5 <- ttestBF(tas_h$newx[tas_h$values.current_group==3 & tas_h$selection==1 & tas_h$novelty==1], tas_h$newx[tas_h$values.current_group==1 & tas_h$selection==1 & tas_h$novelty==1], paired=FALSE, nullInterval = c(-Inf, 0))

tas_ht6 <- ttestBF(tas_h$newx[tas_h$values.current_group==3 & tas_h$selection==1 & tas_h$novelty==2], tas_h$newx[tas_h$values.current_group==1 & tas_h$selection==1 & tas_h$novelty==2], paired=FALSE, nullInterval = c(-Inf, 0))

tas_ht7 <- ttestBF(tas_h$newx[tas_h$values.current_group==3 & tas_h$selection==2 & tas_h$novelty==1], tas_h$newx[tas_h$values.current_group==1 & tas_h$selection==2 & tas_h$novelty==1], paired=FALSE, nullInterval = c(-Inf, 0))

tas_ht8 <- ttestBF(tas_h$newx[tas_h$values.current_group==3 & tas_h$selection==2 & tas_h$novelty==2], tas_h$newx[tas_h$values.current_group==1 & tas_h$selection==2 & tas_h$novelty==2], paired=FALSE, nullInterval = c(-Inf, 0))
#####


#Desire to eat ratings
des_h1 <- lmBF(data=des_h, newx ~ values.current_group * selection * novelty + item + unique_ID, whichRandom = c("item", "unique_ID"))
des_h2 <- lmBF(data=des_h, newx ~ values.current_group * selection + item + unique_ID, whichRandom = c("item", "unique_ID"))
des_h3 <- lmBF(data=des_h, newx ~ values.current_group * novelty + item + unique_ID, whichRandom = c("item", "unique_ID"))
des_h4 <- lmBF(data=des_h, newx ~ values.current_group + novelty * selection + item + unique_ID, whichRandom = c("item", "unique_ID"))
des_h5 <- lmBF(data=des_h, newx ~ values.current_group * novelty + selection + item + unique_ID, whichRandom = c("item", "unique_ID"))
des_h6 <- lmBF(data=des_h, newx ~ values.current_group * selection + novelty + item + unique_ID, whichRandom = c("item", "unique_ID"))
des_h7 <- lmBF(data=des_h, newx ~ values.current_group + selection + novelty + item + unique_ID, whichRandom = c("item", "unique_ID"))
des_h8 <- lmBF(data=des_h, newx ~ values.current_group + selection + item + unique_ID, whichRandom = c("item", "unique_ID"))
des_h9 <- lmBF(data=des_h, newx ~ values.current_group + novelty + item + unique_ID, whichRandom = c("item", "unique_ID"))
des_h10 <- lmBF(data=des_h, newx ~ values.current_group + item + unique_ID, whichRandom = c("item", "unique_ID"))

#Get ouput for all models
des_h_all <- c(des_h1, des_h2, des_h3, des_h4, des_h5, des_h6, des_h7, des_h8, des_h9, des_h10)
des_h_all

BF_eet1 <- lmBF(data=eet_data, newx ~ healthiness * values.current_group * selection * novelty + item + unique_ID, whichRandom = c("item", "unique_ID"))

BF_eet2 <- lmBF(data=eet_data, newx ~ healthiness * values.current_group * selection + item + unique_ID, whichRandom = c("item", "unique_ID"))

BF_eet3 <- lmBF(data=eet_data, newx ~ healthiness * values.current_group * selection + item + unique_ID, whichRandom = c("item", "unique_ID"))

BF_eetx <- lmBF(data=eet_data, newx ~ values.current_group + item + unique_ID, whichRandom = c("item", "unique_ID"))

BF_tas1 <- lmBF(data=eet_data2, newx ~ healthiness * values.current_group * selection * novelty + item + unique_ID, whichRandom = c("item", "unique_ID"))

BF_tas2 <- lmBF(data=eet_data2, newx ~ values.current_group + item + unique_ID, whichRandom = c("item", "unique_ID"))



lmBF(data=)
```


#Function from copying values from previous rows

shift <- function(x, lag) {
  n <- length(x)
  xnew <- rep(NA, n)
  if (lag < 0) {
    xnew[1:(n-abs(lag))] <- x[(abs(lag)+1):n]
  } else if (lag > 0) {
    xnew[(lag+1):n] <- x[1:(n-lag)]
  } else {
    xnew <- x
  }
  return(xnew)
}

##################################################################
transform_x <- function(min, max, x, data)
{newx <- (x - min)/(max-min)
newx <- newx * 100
if (2 %in% data$values.eval_side) {newx <- abs(newx - 100)}
newdata <- as.data.frame(cbind(data, newx))
newx <- as.numeric(newdata$newx)
return(newdata)
}


step1 <- function(data)
{
  names(data)[1] <- "participant" #required for trimr functions
  names(data)[2] <- "congruence"
  names(data)[3] <- "liking"
  names(data)[4] <- "prime_type"
  names(data)[5] <- "healthiness"
  names(data)[6] <- "rt" #required for trimr functions
  names(data)[7] <- "accuracy"
  names(data)[9] <- "rating"
  names(data)[10] <- "prime"
  names(data)[11] <- "block"
  names(data)[32] <- "target"
  
  return(data)
  
}

---
title: "Untitled"
author: "Loukia Tzavella"
date: "15/11/2017"
output: html_document
---

* Required packages

```{r}
#Please note that certain packages may not be compatible with your version of R
#R should be updated to the latest version- this script uses R version 3.4.3 (2017-11-30)

required.packages <- c("BayesFactor", "plyr", "here", "data.table", "reshape2", "ggplot2", "viridis", "cowplot")
new.packages <- required.packages[!(required.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)>0) {install.packages(required.packages)}

require(BayesFactor)
require(plyr)
require(here)
require(data.table)
require(reshape2)
require(ggplot2)
require(viridis)
require(cowplot)
```

* Read csv files from the R project sub-folder and add all dataframes to a list

```{r}
files <- list.files(path="~/Library/Mobile Documents/com~apple~CloudDocs/CHAPTER 2/CH2_DATA/all_csvs", all.files = TRUE, full.names = FALSE, no.. = TRUE, pattern = "\\.csv$")

#Delete extension based on the number of characters before ".csv"- all names should have an equal number of characters
names <- substr(files, 1, 6)

#This loop will create a data frame for each .csv file found in your filepath

#might require an alternative for this- loop is too slow for so many data files

all_data <- list() 


for (i in names) {
  filepath <- file.path("~/Library/Mobile Documents/com~apple~CloudDocs/CHAPTER 2/CH2_DATA/all_csvs/", paste(i, ".csv", sep =""))
  all_data[[i]] <- read.csv(filepath, header=T, se="\t")
}
```

Check group numbers
```{r}
group1 <- all_data[sapply(all_data, function(x) all(x$values.current_group == 1))]
group2 <- all_data[sapply(all_data, function(x) all(x$values.current_group == 2))]
group3 <- all_data[sapply(all_data, function(x) all(x$values.current_group == 3))]
```

Check exclusion criteria- i.e. not include in main analyses:

vegan not available- wasn't recorded in raw data- only summary data
```{r}
group1 <- group1[sapply(group1, function(x) any(x$values.psych_disorders==2))]
group1 <- group1[sapply(group1, function(x) any(x$values.psych_drugs=="None"))]
group1 <- group1[sapply(group1, function(x) any(x$values.eating==4))]

group2 <- group2[sapply(group2, function(x) any(x$values.psych_disorders==2))]
group2 <- group2[sapply(group2, function(x) any(x$values.psych_drugs=="None"))]
group2 <- group2[sapply(group2, function(x) any(x$values.eating==4))]

group3 <- group3[sapply(group3, function(x) any(x$values.psych_disorders==2))]
group3 <- group3[sapply(group3, function(x) any(x$values.psych_drugs=="None"))]
group3 <- group3[sapply(group3, function(x) any(x$values.eating==4))]

#It works! -- #DEMOGRAPHICS FILE NOT IN HERE!

veg_include <- unique(demographics$subject[demographics$vegan_criterion_response==2])
psych_include <- unique(demographics$subject[demographics$psych_disorders_criterion_response==2])
drug_include <- unique(demographics$subject[demographics$psych_drugs_criterionoption4_response=="None"])

group1 <- group1[sapply(group1, function (x) any(x$subject %in% veg_include))]
group1 <- group1[sapply(group1, function (x) any(x$subject %in% veg_include))]
group1 <- group1[sapply(group1, function (x) any(x$subject %in% veg_include))]


test <- all_data[sapply(all_data, function(x) any(x$latency[x$values.frame_go==4]==17))]
test2 <- all_data[sapply(all_data, function(x) any(x$latency[x$values.frame_signal==2]==50))]

```
Other exclusions:

Timing-related exclusions:

* Refresh rate is not 60 Hz--> change to duration of each frame- i.e. it has to be 17 ms 
* Trials with stimulus onset times with a delay greater than 150 ms will be removed; 
  
  -75% of signal trials should be valid for each cell of the design (i.e., selection condition x signal-onset distance)- 12 out of 16 trials 
  -75% of trials in each cell of the design for the go test *Important for later analyses* Blocks should be matched- responses for a specific type of trial (e.g., stimulus)
   should be excluded from both blocks
  -Minimum 6 out ot 8 trials for each design cell in the eval task (tastiness and desire to eat ratings considered seperately)


*Very important*
The number of valid trials will be affected by other exclusions as well: 
Missing or inaccurate responses on the CEE task and go test blocks- so the ITI checks should ideally happen after these have been looked at

Performance on the go test is important because we need enough trials for RTs to be analysed- and that refers to correct trials only
For the CEE task, participants might not respond on time (i.e., 'missing' responses)

*Problem?* No exclusions were pre-registered for the number of trials generally needed for the CEE task

*Criteria* After performance exclusions have been made we can proceed to data reductions. 

Performance exclusions for training data: 

* Proportion of correct responses in go trials < 85%
* Proportion of correct responses in stop trials < 65% 
* Proportion of correct responses in stop-change trials < 50% 

* No exclusions for go test performance? 

  Discuss w/ Chris- this was never explicitly declared- the same crtiterion as in go trials (training) could be applied 



> survey$subject <- make.unique(as.character(survey$subject), sep = "_")

> copy <- lapply(copy, function(x) make.unique(as.character(x$subject), sep="_"))

```{r}
training_data <- lapply(all_data, subset, (blockcode=="go_training" | blockcode=="stop_training" | blockcode=="change_training"))
go_test_data <- lapply(all_data, subset, blockcode=="go_test")


group1_train <- lapply(group1, subset, blockcode=="go_training")
group2_train <- lapply(group2, subset, blockcode=="stop_training")
group3_train <- lapply(group3, subset, blockcode=="change_training")

#Recode accuracy values to only have 1s (correct) and 0s (incorrect)

group1_train <- lapply(group1_train, transform, accuracy = ifelse(values.ns_accuracy==1, "1", "0"))

group2_train <- lapply(group2_train, transform, ns_accuracy = ifelse(values.ns_accuracy==1, "1", "0"))
group2_train <- lapply(group2_train, transform, ss_accuracy = ifelse(values.ss_accuracy==1, "1", "0"))

group3_train <- lapply(group3_train, transform, ns_accuracy = ifelse(values.ns_accuracy==1, "1", "0"))
group3_train <- lapply(group3_train, transform, sc_accuracy = ifelse(values.sc_accuracy==1, "1", "0"))

#If values.iti is judged and not only values.trial_ms then we can apply this to the go_test and eval_task data 
group1_train <- lapply(group1_train, transform, iti_check = ifelse(values.iti<800 & values.iti>600, "700", ifelse(values.iti>400 & values.iti<600, "500", "NA")))

group2_train <- lapply(group2_train, transform, iti_check = ifelse(values.iti<800 & values.iti>600, "700", ifelse(values.iti>400 & values.iti<600, "500", "NA")))

group3_train <- lapply(group3_train, transform, iti_check = ifelse(values.iti<800 & values.iti>600, "700", ifelse(values.iti>400 & values.iti<600, "500", "NA")))

#Change accuracy variable structure into integer format 

group1_train <- lapply(group1_train, transform, accuracy = as.numeric(as.character(accuracy)))

group2_train <- lapply(group2_train, transform, ns_accuracy = as.numeric(as.character(ns_accuracy)))
group2_train <- lapply(group2_train, transform, ss_accuracy = as.numeric(as.character(ss_accuracy)))

group3_train <- lapply(group3_train, transform, ns_accuracy = as.numeric(as.character(ns_accuracy)))
group3_train <- lapply(group3_train, transform, sc_accuracy = as.numeric(as.character(sc_accuracy)))


#For participant exclusions we only need to know the 'length' of removed elements from each type of task- see criteria above

###

group1_train_acc <- lapply(group1_train, subset, values.frame_go==112 | values.frame_signal==112)
group1_train_acc  <- lapply(group1_train_acc , droplevels)

group2_train_acc <- lapply(group2_train, subset, values.frame_go==112 | values.frame_signal==112)
group2_train_acc  <- lapply(group2_train_acc , droplevels)

group3_train_acc <- lapply(group3_train, subset, values.frame_go==112 | values.frame_signal==112)
group3_train_acc  <- lapply(group3_train_acc , droplevels)


group1_means <- ldply(group1_train_acc, function(x) goPC= mean(x$accuracy))
group2_means <- ldply(group2_train_acc, function(x) {c(stopPC = mean(x$ss_accuracy[x$values.frame_signal==112]), goPC = mean(x$ns_accuracy[x$values.frame_go==112]))})
group3_means <- ldply(group3_train_acc, function(x) {c(changePC = mean(x$sc_accuracy[x$values.frame_signal==112]), goPC = mean(x$ns_accuracy[x$values.frame_go==112]))})


train_include <- unique(means$.id[means$V1>=0.85])

#This doesn't give us the subject IDs- you can subset the whole element though and select only the names to be included
#e.g., sub001 is the .id name from the accuracy data frame but also the name of the dataframe within the list corresponding to that participant 


test3 <- subset(group1_train, names(group1_train) %in% train_include)



#refactor all variables
```
