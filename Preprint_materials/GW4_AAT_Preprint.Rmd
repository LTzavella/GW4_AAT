---
title             : "Does inhibitory control training have an indirect effect on automatic action tendencies for unhealthy foods?"
shorttitle        : "ICT effects on food action tendencies"

author: 
  - name          : "Loukia Tzavella"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Cardiff University Brain Research Imaging Centre, CF24 4HQ, UK"
    email         : "tzavellal@cardiff.ac.uk"
  - name          : "Christopher D. Chambers"
    affiliation   : "1"
  - name          : "Natalia Lawrence"
    affiliation   : "2"
  - name          : "Katherine S. Button"
    affiliation   : "3"
  - name          : "Elizabeth Hart"
    affiliation   : "4"
  - name          : "Natalie Holmes"
    affiliation   : "4"
  - name          : "Kimberley Houghton"
    affiliation   : "4"
  - name          : "Nina Badkar"
    affiliation   : "2"
  - name          : "Ellie Macey"
    affiliation   : "2"
  - name          : "Amy-Jayne Braggins"
    affiliation   : "3"
  - name          : "Felicity Murray"
    affiliation   : "2"
  - name          : "Rachel C. Adams"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "Cardiff University Brain Research Imaging Centre, CF24 4HQ, UK"
  - id            : "2"
    institution   : "School of Psychology, University of Exeter, EX4 4QG, UK"
  - id            : "3"
    institution   : "Department of Psychology, University of Bath, BS2 7AY, UK"
  - id            : "4"
    institution   : "School of Psychology, Cardiff University, CF10 3AT, UK"

authornote: |
  The research project was conducted as part of the GW4 Undergraduate Psychology Consortium 2017/2018 and was supported by the European Research Council (Consolidator 647893; C.D.C.). We also gratefully acknowledge Teaching Development Funding, from the faculty of Humanities and Social Sciences at the University of Bath for funding travel and room hire costs for the consortium meetings.

abstract: | 

  Dual-process models indicate that automatic and controlled processes, such as automatic action tendencies and inhibitory control, play a paramount role in determining behaviour towards appetitive cues and have led to the development of behaviour change interventions. A prominent paradigm for strengthening response inhibition is inhibitory control training (ICT), such as the go/no-go training task. In the food domain, ICT studies have shown that appetitive stimuli can be devalued during training through a reduction in approach bias that can then facilitate successful response ihibition during the task. The primary aim of the study was to explore this further by testing whether ICT can have an indirect effect on automatic action tendencies, as measured with an approach-avoidance task (AAT). Specifically, we hypothesized that approach bias could be reduced for unhealthy foods associated with response inhibition after training. Secondary outcomes of ICT included impulsive food choices and food evaluations (i.e., liking). Unhealthy foods were randomly assigned to training conditions that manipulated the signal-stimulus mappings, as go (100\% no-signal trials), no-go (100\% signal trials), or control foods (50%-50%). AAT blocks were presented before and after training and participants were instructed to respond to an irrelevant-feature of the stimuli (portrait or landscape) by pushing or pulling the computer mouse, which reflected avoidance and approach responses respectively. Pre-registered analyses showed no effects of ICT on AAT bias scores and only anecdotal evidence for a devaluation effect of no-go foods. We found that the probability of choosing a no-go food after training was lower than that of choosing a control food, and there was evidence for contingency learning during training (manipulation check). Exploratory analyses yielded a number of methodological considerations for both ICT and AAT protocols as well as recommendations and directions for future research. 
  
keywords          : "inhibitory control training, go/no-go, food devaluation, action tendencies, approach bias"
wordcount         : "X"

bibliography      : ["references.bib"]

floatsintext      : yes
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf
includes:
     after_body: "appendix.tex"
header-includes:
- \usepackage{xcolor}
- \usepackage{multicol}
- \usepackage{enumitem}
  \setlist{nosep}
- \usepackage[font=footnotesize,labelfont=bf]{caption}
- \usepackage{float}
- \usepackage{amsmath}
- \usepackage{soul}
- \usepackage{caption}
- \usepackage{booktabs}
- \raggedbottom
---

```{r load_pkgs, message=FALSE, include=FALSE}
# List of packages required for this analysis
pkg <- c("dplyr", "ggplot2", "knitr", "bookdown", "papaja", "devtools", "kableExtra", "devtools")
# Check if packages are not installed and assign the
# names of the packages not installed to the variable new.pkg
new.pkg <- pkg[!(pkg %in% installed.packages())]
# If there are any packages in the list that aren't installed,
# install them
if (length(new.pkg))
  install.packages(new.pkg, repos = "http://cran.rstudio.com")

# Load packages 
require(dplyr)
require(ggplot2)
require(knitr)
require(bookdown)
require(papaja)
require(devtools)
require(kableExtra)
```

# Introduction {#introduction}

\par

The recent rise in overweight and obesity rates can primarily be ascribed to the over-consumption of energy-dense foods that are high in fat, sugar and salt content [@who_obesity_2018], as individuals are constantly exposed to visual cues of such foods in the environment (e.g., through advertisements) and this often leads to increased food intake [@havermans_pavlovian_2013]. A theoretical explanation for this phenomenon has been provided by the dual-process model frameworks which posit that behaviour is determined by the interaction of impulsive (*automatic*) and reflective (*controlled*) cognitive processes [@strack_reflective_2004; @kakoschke_combined_2015]. For example, over-consumption of unhealthy foods can be attributed to heightened approach bias for food cues in the environment, which can result in increased food intake if these automatic action tendencies are not regulated via controlled processes, such as inhibitory control [@kakoschke_effect_2017]. Such theoretical frameworks have led to the development of behaviour change interventions for unhealthy eating behaviours that target either automatic or controlled processing, that is approach bias modification and inhibitory control training respectively [see @kakoschke_approach_2017; @jones_cognitive_2018 for recent reviews]. The primary aim of the present study was to investigate the interaction between automatic and controlled processing in the context of inhibitory control training (ICT). It was assumed that strengthening inhibitory control could influence automatic action tendencies towards unhealthy foods after training. To establish whether the employed ICT paradigm was effective effects of training on impulsive food choice and liking were also examined. 

\par
In the dual-process model frameworks, unhealthy eating behaviours may be explained by a weak reflective system and/or a strong impulsive system [e.g., @lawrence_nucleus_2012-1; @nederkoorn_specificity_2012], which can often be in conflict. For example, automatic attentional (e.g., attending to the cue) and motivational (e.g., approaching the food) processes would antagonize the controlled process of considering long-term goals such as losing weight when an individual has to decide on an action, that is to eat or not eat the food [@kakoschke_combined_2015]. This study focuses on an automatic process known as approach bias, which is the automatic action tendency to approach an appetitive (food) cue in the environment, rather than avoid it [@wiers_automatic_2013]. Approach bias has been demonstrated for a variety of appetitive cues, such as cigarettes [e.g., @bradley_affective_2008], alcohol [e.g., @wiers_retraining_2010] and cannabis [e.g., @field_selective_2006]. In the food domain, there is evidence for the existence of approach bias for a variety of energy-dense foods [@brignell_attentional_2009; @kemps_approach_2015; @kemps_implicit_2013; @veenstra_restrained_2010]\footnote{There is great variability in terms of methodology for the assessment of both approach bias and inhibitory control in reported studies and therefore the replicability of certain findings is questionable. This and similar issues are presented in the \textit{\nameref{discussion}.}}. Interestingly, @kakoschke_combined_2015 found that approach bias alone did not predict increased intake of unhealthy foods, but it was the interaction between approach bias and inhibitory control that was the significant determinant of subsequent behaviour. The authors report that approach bias had the expected effect on food intake only for participants with low inhibitory control. As an important component of controlled processing, inhibitory control has been defined as “the ability to inhibit a behavioural impulse in order to attain higher-order goals, such as weight loss” [@houben_too_2012, p. 550] and encompasses several elements, such as response inhibition and cognitive flexibility [see @bartholdy_systematic_2016]. Inhibitory control capacity is often measured via response inhibition paradigms, such as the go/no-go task  and stop-signal task, and has been associated with unhealthy eating behaviours [e.g., @jasinska_impulsivity_2012;  @guerrieri_influence_2007; @hall_executive_2012]. @nederkoorn_control_2010 showed that strong implicit preferences for snacks paired with low 'inhibitory control capacity' predicted weight gain over one year. Overall, there is evidence to suggest that both inhibitory control and motivational processes are important determinants of eating-related behaviour. 

\par
Complementary evidence for the role of automatic and controlled processes in the regulation of eating behaviours stems from the line of research dedicated to the development of health behaviour change interventions. Approach bias modification training is commonly delivered via an approach-avoidance task [AAT; @neumann_approach_2000; @rinck_approach_2007; @wiers_should_2013] and has been applied to several unhealthy behaviours involving appetitive cues, such as alcohol consumption and cigarette smoking [e.g., @wiers_retraining_2011; @wittekind_approach-avoidance_2015]. The AAT is assumed to capture automatic action tendencies when participants are instructed to respond to an irrelevant feature of a presented picture, such as the orientation (portrait or landscape), by pulling or pushing a joystick [@wiers_automatic_2013]. The AAT can also pair actions with visual feedback, so that the picture gets bigger when participant pull the joystick towards them (zoom-in) and gets smaller when they push it away (zoom-out). Arm extension could indicate an approach response towards an appetitive food (object-reference) or an avoidance response when the food is pushed away from the body/self [self-reference; @phaf_approach_2014] and thus visual feedback provides the self-reference attribute to the responses (e.g., object comes closer to one’s body). The 'zooming' feature disambiguates the mapping of responses to approach and avoidance actions, whereby pulling the joystick represents approach and pushing it reflects avoidance [@neumann_approach_2000]. In AAT training, contingencies between actions and stimuli are manipulated so that appetitive cues are associated with push actions (avoidance) and neutral items are paired with pull actions (approach). Studies employing various AAT protocols have found that training can be effective in re-training approach bias for foods [@brockmeyer_approach_2015-1; @kemps_implicit_2013] and even reduce food intake in the laboratory [@schumacher_bias_2016; see @kakoschke_approach_2017 for review].

\par
In the context of controlled processes, ICT interventions involve cue-specific go/no-go or stop-signal tasks whereby participants are instructed to make a speeded choice response to appetitive stimuli such as foods or alcohol, but to withhold that response when a visual, or auditory, signal is presented. Signal-stimulus mappings are manipulated so that appetitive cues (e.g., unhealthy foods) are consistently paired with a stop signal. Stopping to unhealthy foods has been shown to reduce food consumption [@adams_training_2017; @houben_chocolate_2015; @houben_training_2011; @lawrence_stopping_2015; @veling_using_2011; also see @allom_does_2016 for meta-analysis] and promote healthy food choices in the laboratory [@veling_stop_2013; @veling_training_2017]. ICT protocols have even been associated with increased weight loss [@lawrence_training_2015; @veling_targeting_2014]. A potential mechanism of action behind ICT effects on food consumption is stimulus devaluation [@veling_what_2017], whereby the evaluations of appetitive foods are reduced during training to facilitate performance when response inhibition is required [e.g., @chen_how_2016]. A possible explanation for this devaluation effect is provided by the Behaviour Stimulus Interaction (BSI) theory which posits that food stimuli are devalued when negative affect is induced to resolve the ongoing conflict between triggered approach reactions to appetitive foods and the need to inhibit responses towards those stimuli [@chen_how_2016; @veling_what_2017; @veling_when_2008]. When a food is devalued, the approach bias towards that cue is reduced and therefore inhibition can successfully take place. Would it be possible for this reduction in approach bias to be learned via ICT paradigms? 

\par
This study attempts to answer this question by employing a go/no-go training paradigm with unhealthy food stimuli and measure automatic action tendencies via an AAT before and after training to establish whether individuals show reduced approach bias for the foods associated with response inhibition. If an approach action tendency is consistently reduced through devaluation to facilitate inhibition of responses towards appetitive foods, then ICT may have an indirect effect on approach bias. It would also be of interest to examine whether consistent pairing of appetitive food stimuli with go responses would increase approach bias towards them after training. Additional theoretical ground for this research question has been adopted from the concept of an 'associative stop system', whereby stimuli associated with stopping can be devalued through an interaction of a stop system and an aversive system [see @verbruggen_inhibitory_2014]. Consistent with previous ICT literature, the study also examined impulsive food choice and food liking (i.e., stimulus devaluation manipulation check) as secondary training outcomes.

# Hypotheses {#hypotheses}
All hypotheses described in this section are confirmatory and have been pre-registered\footnote{Exact hypotheses from the pre-registered protocol have been re-ordered according to outcomes for clarity. There were no deviations from the protocol for the hypotheses and corresponding statistical tests, with the exception of minor alterations regarding the supplementary frequentist statitics (see \textit{\nameref{prereg_analyses}}).} on the Open Science Framework (https://osf.io/wav8p/). Effects of ICT (go/no-go training; see \textit{\nameref{gng}}) on automatic action tendencies (see \textit{\nameref{aat}}) and liking (see \textit{\nameref{food_ratings}}) for unhealthy foods were investigated using change scores from pre-to post-training for both outcomes (H1, H3). The training condition was also expected to have an effect on food choice behaviour (H2; see \textit{\nameref{food_choice}}). The study assessed contingency learning mechanisms for the training paradigm, as a manipulation check (H4).  

## Training effects on automatic action tendencies

The primary outcome measure in the study was the change in automatic action tendencies from pre-to post- ICT training for the foods associated with different conditions (go, no-go and control - see Figure \ref{fig:procedure}). Action tendencies were indirectly measured via the AAT and approach-avoidance bias scores were obtained by subtracting the cmedian response times (RTs) in avoid trials (push action) from the RTs in approach trials (pull action) at the participant level (correct responses only), for each training condition and then calculating the change from pre-to post-training. It was hypothesized that ICT training would lead to a reduction in approach bias for no-go goods and potential increase in approach bias for go goods compared to the control foods. 

\noindent H1. There will be *moderate* evidence for an effect of training condition (go, no-go, control) on the change in approach-avoid bias scores from pre-to post-training.
\begin{itemize}
\item[H1a.] Participants will show a reduction in approach bias for no-go foods compared to the control foods, from pre-to post- training.
\item[H1b.] Participants will have increased approach bias towards go foods relative to the control foods, from pre-to post- training.
\end{itemize}

## Training effects on impulsive food choices

As a secondary outcome, the effects of ICT on impulsive food choices for unhealthy foods were tested by comparing the probabilities of choosing a food from each training condition. 

\noindent H2. It was expected that after ICT participants would show reduced impulsive choices for no-go foods and increased choices for go foods relative to control foods. 
\begin{itemize}
\item[H2a.] The probability of choosing a no-go food will be lower than the probability of choosing a control food.
\item[H2b.] The probability of choosing a go food will be higher than the probability of choosing a control food.
\end{itemize}

## Manipulation check 1: Stimulus devaluation

The mean change in food liking ratings from pre-to post-training was examined for each training condition in order to test whether no-go training led to the devaluation of no-go foods compared to control foods.  It should be noted that this was not a positive control for training effectiveness, as the findings for stimulus devaluation outcomes remain controversial [see @jones_inhibitory_2016 for meta-analysis]. Stimulus devaluation in this study was therefore treated both as a manipulation check for the employed training paradigm and a secondary outcome measure. 

\noindent H3. There will be *moderate* evidence for an effect of training condition (go, no-go, control) on the change in food liking from pre-to post-training.

\begin{itemize}
\item[H3a.] Participants will show reduced liking for no-go foods relative to the control foods, from pre-to post- training.
\item[H3b.] Participants will show increased liking for go foods relative to the control foods, from pre-to post- training.
\end{itemize}

## Manipulation check 2: Contingency learning

Training performance was examined in terms of contingency learning. ICT paradigms, such as the go/no-go training task, might lead to stimulus-response associations and learning can be observed in both reaction times and error rates [e.g., @lawrence_training_2015; see @best_instructed_2019]. The proportion of correct responses on signal trials (i.e., successful stops) and the mean reaction times from no-signal (go) trials were compared for specific training conditions, as stated in the hypotheses below.

\noindent H4. Go/no-go training will result in contingency learning in terms of reaction times on no-signal trials and the percentage of successful inhibitions on signal trials. 
\begin{itemize}
\item[H4a.] The proportion of correct responses on signal trials will be greater for no-go foods compared to the control foods associated with a signal (control\textsubscript{nogo}).
\item[H4b.] Go reaction times will be faster for go foods compared to the no-signal control foods presented on no-signal trials (control\textsubscript{go}).
\end{itemize}

# Methods {#methods}

## Participants {#participants}

\par
255 participants were recruited in total from the University campuses of Cardiff, Bath and Exeter via research participation schemes (e.g., Experimental Management system; EMS) and advertisements (see Figure A1 for recruitment details). Participants recruited through participation schemes received course credits, whereas other individuals were offered entry into a prize draw for one of three £20 shopping vouchers. Participants were informed about the study eligibility criteria and in order to ensure compliance they completed a screening survey in the beginning of the study and provided their consent. They were asked to refrain from eating for 3 hours before the study. Participants had to be at least 18 years of age, be fluent in spoken and written English and have normal or corrected-to-normal vision, including normal colour vision. Participants were excluded if they were dieting at the time of the study, with a weight goal and time-frame in mind, had a current and/or past diagnosis of any eating disorder(s) and had a body-mass-index (BMI) lower than 18.5 kg/m$^{2}$ (i.e., underweight category). The study was approved by the Ethics Committees of Cardiff University, University of Bath and the University of Exeter. 

## Sampling plan {#sampling}

\par
The required sample size was estimated based on a frequentist power analysis conducted for the primary outcome measure (i.e., change in approach-avoidance bias, from pre-to post-training, between go and no-go foods; H1a and H1b) and the stimulus devaluation manipulation check (i.e., change in food liking, from pre-to-post training, between go and no-go foods; H3). Both of these effect sizes were in the medium range and therefore calculations were based on the primary outcome measure. For an expected effect size, other studies that have measured approach bias pre-and post-approach-avoidance training [@becker_approach_2015-1; @schumacher_bias_2016] were considered. Both studies reported an effect size of \textit{$\eta$\textsubscript{p}$^{2}$} = 0.07 which corresponds to a ‘medium’ effect size. @becker_approach_2015-1 also reported two non-significant results, although effect sizes were not provided. Note, however, that @becker_approach_2015-1 compared an active group with 90:10 mapping (i.e., avoidance of 90% for unhealthy trials and 10% healthy trials) to a control group with 50:50 mapping whereas @schumacher_bias_2016 compared a 90:10 active group with a 10:90 control group. A conservative approach was followed for the sample size calculation. Firstly, the effect size was reduced by 33% (i.e., *dz* = 0.34) to account for publication bias [@button_power_2013] and secondly an alpha of .005 was used, which has recently been recommended for any research that cannot be considered a direct replication and can increase the reliability of new discoveries [@benjamin_redefine_2017-1]. Based on a priori power calculations using G*Power [@faul_statistical_2009] it was estimated that a total sample of 149 participants\footnote{Due to the large number of participant exclusions based on mean error rates in the AAT (see Figure A1) and the group testing laboratory setting at Cardiff University, final recruitment led to the expected sample size including 14 more participants (N=163).} was necessary for 90% power. 

\par  
The sampling method and power analysis of the study adopted a conservative frequentist approach, but the pre-registered analyses were based on a Bayesian framework (see \textit{\nameref{prereg_analyses}}). Frequentist analyses were also reported in a supplementary fashion ($\alpha$ = .005). Bayes factors (BFs) informed the interpretations of the results and although debate exists about labelling evidence in terms of BFs [@richard_d._morey_verbal_2015-1], the guidelines by @lee_bayesian_2013 were followed. A threshold of *BF*\textsubscript{10} > 6 was used to indicate *moderate* evidence for the alternative hypothesis relative to the null, and *BF*\textsubscript{10} < 1/6 reflected *moderate* evidence for the null relative to the respective alternative hypothesis. Bayes factor analyses were favoured for drawing conclusions from the study, as they would allow us to interpret null outcomes as evidence of absence when traditional analyses would not make such inferences feasible. 

## Procedure {#procedure}

The study procedure can be seen in Figure \ref{fig:procedure} (panel A). After screening, eligible participants were provided with a short survey (see \textit{\nameref{questionnaires}}) and proceeded to rate all food categories on how much they like the taste (see \textit{\nameref{food_ratings}}). Three blocks of the approach-avoidance task (AAT; see \textit{\nameref{aat}}) were completed before the go/no-go training paradigm was performed (see \textit{\nameref{gng}}). Rated food categories were randomly assigned to three conditions for training: go, no-go and control, as shown in Figure \ref{fig:procedure} (panel B). Post-training, participants were presented with another three blocks of the AAT, provided ratings for all food stimuli again and finally completed a short food choice task (see \textit{\nameref{food_choice}}). At the end of the study, several questionnaires were presented in random order and participants were debriefed about the aims of the study. All study components were programmed using Inquisit Lab [@noauthor_inquisit_2016] and run via Inquisit Web online across data collection sites. 

\begin{figure} [!htb]
\centering
\includegraphics[width=\linewidth]{figures/Figure1.png}
\caption{\textbf{Schematic diagram of the study procedure, go/no-go training and approach-avoidance tasks.} \textbf{A.} After completing the screening and initial survey, participants rated all food stimuli (liking) and proceeded to perform the pre-training approach-avoidance task (AAT) blocks. In the training phase, participants completed six blocks of go/no-go training. The post-training AAT blocks were then presented and followed by food liking ratings. At the end of the study, participants completed a short food choice task and several questionnaires, in random order. \textbf{B.} The go/no-go training paradigm involved go (no-signal) and no-go (signal) trials that occurred with equal probability. On go trials, participants had to respond within 1250ms by pressing the "C" and "M" keys to indicate the picture location (left or right, respectively). On no-go trials, participants were instructed not to respond at all. The inter-trial interval (ITI) was 1250ms. Food categories were randomly assigned to three conditions. Go foods were only paired with no-signal trials and no-go foods were always associated with no-signal trials. Control, or filler, foods were presented in both signal and no-signal trials (50:50).}
\label{fig:procedure}
\end{figure}
\clearpage
\begin{figure}
    \ContinuedFloat
    \captionsetup{labelformat=empty}
    \caption{\textbf{C.} In the AAT, participants were asked to respond according to the format of the presented picture (portrait or landscape). Response-format assignments were approximately counterbalanced across participants. As an example, on approach trials a participant would have to pull the mouse towards them when the picture was in portrait format (approach trial) and push it away from them when the picture was in landscape format. Push and pull actions were paired with visual feedback, that is, zoom-out and zoom-in effects respectively. The maximum reaction time (maxRT) was 1500ms and the ITI was set to 500ms. Participants clicked on a central "X" to begin a trial (self-timed start).}
\end{figure}

## Go/No-go training {#gng}

\par
The Go/No-Go (GNG) training paradigm involved go and no-go responses to six pre-selected appetitive food categories. Food categories differed in terms of taste, so that three foods were savoury (i.e., pizza, crisps, chips) and three foods were sweet (i.e., biscuits, chocolate, cake)\footnote{All study materials are openly available at https://osf.io/wcf4r/}. Two food categories were randomly assigned to each training condition (go, no-go, filler foods) in the beginning of the experiment and food taste was counterbalanced so that each condition had one sweet and one savoury food. There were three training conditions according to the mapping of foods to signal (no-go) and no-signal (go) trials in the GNG. All go foods appeared in go (no-signal) trials and all no-go foods were presented in no-go (signal) trials (see Figure 1, panel C). Control, or filler, foods appeared on both go and no-go trials with equal probability (i.e., 50:50). Each food category had three exemplars which appeared twice in each block. 

\par
All foods were presented on either the left or right hand side of the screen within a rectangle for 1250ms, which was the maximum reaction time (maxRT), as shown in Figure \ref{fig:procedure}, panel B. Participants were asked to respond to the location of the food as quickly and as accurately as possible by pressing the "C" and "M" buttons on the keyboard with their left and right index fingers, respectively. The central rectangle remained on the screen throughout the training, including the inter-trial-interval (ITI), which was 1250ms. On signal trials, the rectangle turned bold, indicating that participants should withhold their response. In line with the GNG training paradigm, this signal appeared on stimulus onset (i.e., no delay between stimulus and signal) and stayed on the screen until the end of the trial. A correct response on no-signal trials was registered when participants responded accurately to the location of the food within the maxRT window and a successful stop (i.e., correct signal trial) was considered when participants did not respond at all. Incorrect responses in no-signal trials refer to either to a wrong location judgement or a missed response. Left and right responses were counterbalanced across all manipulated variables for each type of trial. Training was split into 6 blocks of 36 trials (216 trials in total) and lasted approximately 10 minutes with inter-block breaks (15s). Task practice included 12 trials of go and no-go responses (50%-50%) and participants responded to the location of grey squares, instead of food pictures. For the practice trials, accuracy feedback  was provided during the ITI.

## Approach avoidance task {#aat}

\par
The approach-avoidance task (AAT) was adapted from an existent paradigm [@rinck_approach_2007; @wiers_relatively_2009], which involves ‘pull’ (i.e., towards self) and ‘push’ (i.e, away from self) movements of a joystick. Each type of motor response is paired with visual feedback so that when the joystick is pulled, the image gets bigger (zoom-in) and when it is pushed, the image gets smaller (zoom-out). This ‘zooming’ feature acts as an exteroceptive cue of either an approach or avoidance response [@neumann_approach_2000] and complements the proprioceptive properties of the task, where responses requiring arm flexion and extension correspond to approach and avoidance trials, respectively [@wiers_relatively_2009]. The evaluation-irrelevant feature of the paradigm was also incorporated and participants responded according to the format of the picture [portrait or landscape; e.g., @wiers_retraining_2010].

\par
AAT responses involved ‘push’ and ‘pull’ movements of the computer mouse (adaptation of the joystick version). Food stimuli were presented in the centre of the screen and participants were instructed to pull the mouse towards them or push the mouse away from them according to whether the image was in portrait or landscape format (see Figure \ref{fig:procedure}, panel C). Response-format assignments were approximately counterbalanced across participants (45.4\% portrait-approach, 54.6\% landscape-approach). Instructions highlighted moving the mouse cursor until it reaches the end of the screen (top or bottom edge) for a correct response to be registered and making smooth whole-arm movements. Participants had 1500ms to respond after the stimulus appeared. Each trial started with a central ‘X’ on the screen and participants had to click on it to begin (self-timed start). The ITI was 500 ms and there was no delay between the ‘X’ click response and the stimulus onset. In order to account for the natural movement of the mouse, pixel tolerance was added to every mouse movement ($\pm$ 1.25% of display height), including movement initiation in the beginning of the trial. A response in the AAT was registered as correct only when participants completed the correct action (e.g., pull or push) within the maxRT window and also initiated a movement towards the correct direction. Even if the final response was correct, participants could have changed their movement after making an initial error (e.g., pull instead of push the mouse in an 'avoid' trial) and therefore the direction of their initial movement was also taken into account. The complete RT for an AAT trial was defined as the time from the stimulus onset to the successful completion of a response (i.e., completion time) and was used for the bias score calculations (see \textit{\nameref{measures_indices}}). 

\par
Each AAT block consisted of 72 trials and go, no-go and control foods appeared with equal probability for both ‘pull’ (approach) and ‘push’ (avoid) responses. There were 12 approach and 12 avoid trials for each training condition (e.g., no-go) and within those trials, there were six savoury and six sweet foods presented (i.e., three exemplars repeated twice). Three AAT blocks were performed before training (AAT\textsubscript{pre}) and three after training (AAT\textsubscript{post}). There was a number of constraints placed on the quasi-random order of the trials within an AAT block. There were no more than three images of the same food category being presented consecutively and no more than three trials with the same picture format in sequence. AAT practice consisted of 10 trials with grey rectangles instead of food stimuli and accuracy feedback. The screen background for the AAT was black and the task lasted approximately 15 minutes, including the inter-block 15s breaks, where participants received a reminder of the main instructions.


## Food liking ratings {#food_ratings}

\par
Participants provided food liking ratings before and after training using a visual analogue scale (VAS). They rated all foods included in the GNG paradigm according to how much they liked the taste, ranging from 0 (‘not at all’) to 100 (‘very much’). Task instructions encouraged participants to imagine they were tasting the food in their mouth and then rate how much they liked the taste. The order of the presented foods was randomised and each block consisted of 18 trials. Participants completed a block before training and a block after training. 

## Food choice task {#food_choice}

Impulsive food choices were assessed using a food choice task adapted from @veling_stop_2013, which included all food categories from the GNG paradigm (two exemplars per category). The twelve foods were presented on a grid layout and participants had ten seconds to select three foods that they would like to consume the most at that specific time, by clicking on them with the computer mouse. Participants were asked to click on a 'start' button to begin the trial and when a response was registered the selected food stimulus disappeared from the screen. This task element was introduced to prevent participants from deliberating on their choices and changing their initial responses, which would mean that *impulsive* food choices were no longer measured. However, it should be noted that although participants were not informed about the hypothetical nature of their choices, it is highly probable that they would not consider their choices consequential (i.e., they would not think they would get a food item at the end of the study). 

## Survey & Questionnaires {#questionnaires}

\par
Eligible participants were presented with an initial survey to record demographics and other variables for exploratory analyses. The survey consisted of height and weight measurements to calculate participant's body-mass-index (BMI; kg/m$^{2}$), the number of hours since their last meal ('less than 3 hours ago', '3-5 hours ago', '5-10 hours ago', 'more than 10 hours ago') and hunger state at the the time of the study (VAS: 1='Not at all' to 9='Very'). Gender was also recorded with the options of male, female, transgender male, transgender female, gender variant/non-conforming, and an open ended text response for ‘other’.

\par
Several questionnaires were completed by the participants at the end of the study for exploratory analyses, as part of the undergraduate student projects of the GW4 Undergraduate Psychology Consortium 2017/2018. The Barratt Impulsivity Scale [BIS-15; @spinella_normative_2007] was introduced as a measure of impulsivity and the Stop Control Scale [SCS; @de_boer_stop_2011] was used to examine a distinctive element of general trait self-control, referred to as stop control. Other administered questionnaires included the Food Cravings Questionnaire - Trait - reduced  [FCQ-T-r; @meule_short_2014-1], Perceived Stress Scale [PSS; @cohen_global_1983] and the 'food' and 'money' subscales from the Delaying Gratification Inventory [DGI; @hoerger_development_2011].  A correlation matrix of main questionnaire measures and sample characteristics can be found in Appendix \ref{appendix_cormatrix}.


# Analyses

## Measures & indices {#measures_indices}

\par
The mean error rates in no-signal and signal trials as well as mean reaction time in no-signal trials (GoRT) from the GNG informed participant exclusions (see \textit{\nameref{data_exclusions}}). For the contingency learning manipulation check (H4), measures included the proportion of successful stops from signal trials for no-go and control foods which were paired with a signal (control-nogo) and the mean GoRTs for each participant from correct go and control-go trials. 
\par
Performance in the AAT\textsubscript{pre} and AAT\textsubscript{post} blocks was considered only for correct responses. Median RTs for ‘push’ and ‘pull’ responses from all training condition levels were calculated at a participant level\footnote{RTs were recorded continuously from movement initiation to response completion with samples every 33ms (two display refresh rates) to allow dynamic zoom-in/zoom-out effects based on participants' mouse movements. However, a bug was encountered with the version of the software and the temporal resolution at which coordinates and times were recorded was reduced. For this reason, linear interpolation was applied to increase the samples for every trial and obtain more precise RT measures. All details regarding this procedure can be found in the analyses scripts.\hl{will add link later here}}. Medians were used instead of means as they are less sensitive to outliers in RT distributions [also see @wiers_relatively_2009; @wiers_retraining_2010]. The approach-avoidance bias score for each condition was calculated as the difference between the median completion RTs for ‘push’ and’ pull’ responses (MedianRT\textsubscript{push}- MedianRT\textsubscript{pull}). Bias scores were computed for both AAT\textsubscript{pre} and AAT\textsubscript{post} blocks. Positive scores indicate an approach bias towards the foods of interest and negative scores reflect avoidance for those foods. Change scores for approach-avoid biases from pre-to post-training ($\Delta$AAT) were calculated for pre-registered analyses (H1). The proportion of correct responses for each AAT design cell informed participant exclusions and exploratory analyses (see \textit{\nameref{accuracy_aat}}).
\par
Participants were required to choose three foods out of twelve in the food choice task and selections could vary in their number for each training condition (go, no-go, control). Food choices were therefore normalised according to the total number of responses per participant (i.e., proportion). These calculated proportions, which were calculated for each participant were then compared across training conditions. For example, if a participant had chosen two go foods and one filler food, the probability (i.e., calculated proportion) of choosing a go food would be  0.667, the probability of choosing a filler food would be 0.333 and the probability of choosing a no-go food would be 0. Food rating VAS scores were averaged (mean) across the two foods per training condition (i.e., sweet and savoury foods for go, no-go and control conditions) and the three exemplars of each food. Changes in food liking from pre-to-post training ($\Delta$Liking) were compared for pre-registered analyses.

## Data exclusions {#data_exclusions}

\par
Participant-level data exclusions were conducted based on GNG training and AAT performance and participants who met any of the following criteria were excluded from all respective analyses. Participants who had a mean GoRT greater than three standard deviations from the group mean and percentage of correct responses in no-signal trials less than 85% were excluded. Participants were also excluded if their percentage of errors in signal trials was greater than three standard deviations from the group mean and percentage of errors in either pre- or post- AAT blocks greater than 0.25. Additionally, participants who submitted a food rating of 50 (i.e., neutral) for 24 or more trials either pre-or post-training would not be included as multiple such responses could indicate that participants skipped the rating trials by using the default setting of the VAS. 

## Pre-registered analyses {#prereg_analyses}

\par
Data pre-processing and analyses were conducted in R [@R-base] via RStudio [@rstudio] and JASP [@JASP2018:1]. Pre-registered analyses are described under their pre-specified hypotheses, as previously presented (see \textit{\nameref{hypotheses}}). For all Bayesian paired samples t-tests mentioned hereinafter, a prior with the $\sqrt{2/2}$ scale parameter for the half-Cauchy distribution was used.

\noindent H1. The effect of training condition on the change in approach-avoid bias scores from pre-to post-training was examined using a Bayesian Repeated Measures ANOVA with the default prior settings [@rouder_default_2012; @rouder_model_2016] and participants treated as a nuisance term. 
\begin{itemize}
\item[H1a.] $\Delta$AAT\textsubscript{nogo} <  $\Delta$AAT\textsubscript{control}  
\item[H1b.] $\Delta$AAT\textsubscript{go} >  $\Delta$AAT\textsubscript{control}
\end{itemize}

\noindent H2. Two Bayesian paired samples t-tests were conducted for the mean proportions of selected foods in the go and no-go training condition compared to the control. 
\begin{itemize}
\item[H2a.] p(no-go) < p(control)
\item[H2b.] p(go) > p(control)
\end{itemize}

\noindent H3. The effect of training condition on the change in food liking from pre-to post-training was examined using a Bayesian Repeated Measures ANOVA, consistent with H1.
\begin{itemize}
\item[H3a.] $\Delta$Liking\textsubscript{nogo} < $\Delta$Liking\textsubscript{control}
\item[H3b.] $\Delta$Liking\textsubscript{go} > $\Delta$Liking\textsubscript{control}
\end{itemize}


\noindent H4. Contingency learning during go/no-go training was examined using Bayesian paired-samples t-tests for the percentage of successful inhibition trials and go reaction times. 
\begin{itemize}
\item[H4a.] PCsignal\textsubscript{nogo} > PCsignal\textsubscript{control-nogo}
\item[H4b.] GoRT\textsubscript{go} < GoRT\textsubscript{control-go}
\end{itemize}

The evidential value of confirmatory findings was solely determined by the Bayesian tests outlined in this section, as previously explained (see \textit{\nameref{sampling}}). Frequentist tests were conducted in order to further the reproducibility of findings (e.g., potential use in meta-analyses). Paired samples t-tests were two-tailed, in line with the reported power analysis\footnote{Although Bonferroni corrections were pre-registered for paired sample t-tests following Bayesian Repeated Measures ANOVAs, there were only two planned contrasts for each ANOVA and reflected distinct hypotheses about the data. Therefore, such corrections were not applied for the reported p-values.} Assumptions for repeated measures ANOVAs  (H1 and H3) were checked in line with the pre-registered analysis plan and no violations were observed. Contingency plans were not considered in case the normality assumption was violated for paired t-tests (Shapiro Wilk test: *p* $\leq$ .005), but appropriate exploratory analyses were conducted and reported in the \textit{\nameref{robust}} section\footnote{For other analyses reported in the \textit{\nameref{exploratory}} section, p-values from Wilcoxon signed-rank tests are reported as \textit{p\textsubscript{W}} in a supplementary manner.}. A minor deviation from the pre-registered frequentist analyses was that paired sample t-tests for H1a and H1b were conducted irrespective of the Repeated Measures ANOVA results (H1) for completeness. 

# Results

## Sample characteristics

The final sample consisted of 163 participants (80.98\% female). Detailed participant-level exclusions are presented in Figure A1. Participants had on average a healthy BMI (*M* = 22.88, *SD* = 2.98, range = 18.54 - 32.36) and their mean age was 22.39 (*SD* = 9.04, range = 18 - 59). 108 participants (66.26\%) reported that they had their last meal 3-5 hours before the study and hunger levels at the beginning of the study were not particularly high (*M* = 5.70, *SD* = 2.22). However, 24 participants (14.72\%) did not adhere to the instruction not to eat three hours before the study, as they reported having their last meal "less than 3 hours ago". 

## Findings from confirmatory analyses  {#confirmatory_findings}

### Training outcomes {#training_outcomes}
\par
There was *strong* evidence for the absence of a general effect of go/no-go training condition on the change in approach-avoidance bias scores [*BF*$_{01}$ = 16.06; *F*(2, 324) = 1.01, *p* = 0.365]. Results for paired comparisons are shown in Table \ref{tab:prereg}. There was *moderate* evidence that the change in bias scores for no-go foods ($\Delta$AAT\textsubscript{nogo}; *M* = -3.31, *SD* = 62.91) was not reduced compared to the change for filler foods ($\Delta$AAT\textsubscript{control}; *M* = -1.81, *SD* = 59.55). Similar to H1a, there was *strong* evidence for the null compared to the alternative for H1b. The change in bias scores for go foods ($\Delta$AAT\textsubscript{go}; *M* = -10.47, *SD* = 59.57) was not greater than the change for filler foods. Approach-avoidance bias scores pre- and post- training across training conditions can be visualised using rainclouds\footnote{The raincloud plots have been created using existing code and guidelines [@micah_allen_raincloudplots_2018; @10.12688/wellcomeopenres.15191.1].} in Figure \ref{fig:raincloud_bias}. 
\par
The effect of training on impulsive food choices was examined for no-go and go foods compared to control, as stated in H2a and H2b respectively. There was *extreme* evidence that the probability of choosing a no-go food (*M* = 0.21, *SD* = 0.27) was lower than the probability of choosing a filler food (*M* = 0.36, *SD* = 0.31) after training\footnote{There was a missing value for this analysis as one participant did not complete the food choice task.} (see Table \ref{tab:prereg}). In contrast, there was only *anecdotal* evidence that probability of choosing a go food (*M* = 0.44, *SD* = 0.33) was not higher than the probability of choosing a filler food. Differences in food choice probabilities can be seen in Figure \ref{fig:choices}.


\begin{figure} [!htb]
\centering
\includegraphics[width=\linewidth]{figures/Figure2.png}
\captionof{figure}{\textbf{Raincloud plot of the approach-avoidance bias scores pre- and post- training across training conditions.} There were no differences between the sample mean changes in approach-avoidance bias scores for no-go and go foods compared to control (filler) foods, as shown by the dashed lines. At a closer inspection, individual bias scores do not seem to be clustered around the positive end of the distribution as it would be expected for appetitive unhealthy foods, but actually show less dispersion around zero. Exploratory analyses confirmed that baseline bias scores did not statistically deviate from zero (see \textit{\nameref{baseline_bias}}). \textit{Note.} The `split-half violin' elements in the plot show smoothed distributions and boxplot vertical lines represent the range, excluding outliers based on the Interquantile Range. Square boxes have been added to depict the sample means, connected with dashed lines across training conditions.}
\label{fig:raincloud_bias}
\end{figure} 


\begin{figure} [!htb]
\centering
\includegraphics[width=\linewidth]{figures/Figure3.png}
\captionof{figure}{\textbf{Boxplots showing the food choice probabilities across training conditions.} The boxplots with corresponding jittered individual data points clearly show that the probability of choosing a no-go food after training was lower than the probability of choosing control food [H2a]. Contrary to initial predictions, the average choice probability was not higher for go foods relative to the control [H2b]. \textit{Note.} The `split-half violin' elements in the plot show smoothed distributions and boxplot vertical lines represent the range, excluding outliers based on the Interquantile Range.} 
\label{fig:choices}
\end{figure} 

### Manipulation checks for training {#manipulation_checks}

\par
As a first manipulation check for training outcomes, it was investigated whether GNG changed the evaluations of foods associated with signal and no-signal trials compared to the evaluations of filler foods which were paired with either type of trial with equal probability (control).  There was only *anecdotal* evidence for the absence of a general effect of training condition on the changes in liking from pre- to post- training [H3; *BF*\textsubscript{01} = 2.89; *F*(2, 324) = 2.90, *p* = 0.057]. The change in liking scores from pre-to post-training for nogo foods ($\Delta$Liking\textsubscript{nogo}; *M* = -4.16; *SD* = 9.51) was only slightly reduced compared to change in liking for filler foods ($\Delta$Liking\textsubscript{control}; *M* = -2.61, *SD* = 8.77), and there was only *anecdotal* evidence for this effect (H3a; see Table \ref{tab:prereg}). The change in liking scores from pre-to post-training for go foods ($\Delta$ Liking\textsubscript{go}; *M* = -2.87, *SD* = 10.15), however, was not greater than the change for filler foods as originally expected. Instead, there was *strong* evidence for the null hypothesis compared to the alternative (H3b). 

\par
In order to validate whether the implemented go/no-go training paradigm led to stimulus-response associations (i.e., contingency learning), we tested whether the percentage of correct responses for no-go foods (i.e., successful inhibitions) would be greater compared to the percentage of correct responses for filler foods associated with signal trials (H4a). There was *extreme* evidence that participants had on average more successful inhibitions for no-go foods (PCsignal\textsubscript{nogo}; *M* = 0.97, *SD* = 0.03) than filler foods 
(PCsignal\textsubscript{control-nogo}; *M* = 0.96, *SD* = 0.04). Results are graphically presented in Figure \ref{fig:signal_accuracy}. For H4b, it was examined whether mean reaction times would be reduced for go foods (GoRT\textsubscript{go}; *M* = 507.00, *SD* = 70.48) compared to filler foods associated with no-signal trials (GoRT\textsubscript{control-go}; *M* = 515.00, *SD* = 75.51) and there was *extreme* evidence for such an effect. Therefore, contingency learning was observed in the employed GNG paradigm for both reaction time and accuracy outcomes.  

\begin{table}[!htb]
	\centering
	\caption{Results for all pre-registered hypotheses and respective statistical tests}
	\label{tab:prereg}
	{
		\begin{tabular}{lrrrrrrrr}
			\toprule
		 &   &  &  &  &  & \multicolumn{2}{c}{95\% CI for \textit{d}} & \\
			\cline{7-8}
			 & \textit{BF}\textsubscript{10} & \textit{t} & \textit{df} & \textit{p} & \textit{d} & Lower & Upper  & Evidence interpretation \\
			\cmidrule(r){1-9}
			H1a & 0.107 & -0.25 & 162 & 0.805 & -0.02 & -0.17 & 0.13 & \textit{Moderate} evidence for H\textsubscript{0} \\
			H1b & 0.039 & -1.35 & 162 & 0.179 & -0.11 & -0.26 & 0.05 & \textit{Strong} evidence for H\textsubscript{0} \\
			H2a & 247.782 & -3.93 & 161 & < .001 & -0.31 & -0.47 & -0.15 & \textit{Extreme} evidence for H\textsubscript{1} \\
			H2b & 0.849 & 1.82 & 161 & 0.070 & 0.14 & -0.01 & 0.30 & \textit{Anecdotal} evidence for H\textsubscript{0} \\
			H3a & 2.648 & -2.38 & 162 & 0.019 & -0.19 & -0.34 & -0.03 & \textit{Anecdotal} evidence for H\textsubscript{1} \\
			H3b & 0.067 & -0.37 & 162 & 0.715 & -0.03 & -0.18 & 0.13 & \textit{Strong} evidence for H\textsubscript{0} \\
			H4a & 140.254 & 3.77 & 162 & < .001 & 0.30 & 0.14 & 0.45 & \textit{Extreme} evidence for H\textsubscript{1} \\
			H4b & 3973.214 & -4.66 & 162 & < .001 & -0.37 & -0.52 & -0.21 & \textit{Extreme} evidence for H\textsubscript{1} \\
			\bottomrule
		\end{tabular}
	}
		\begin{tablenotes}[para]
\footnotesize{\textit{Note.} Evidence is interpreted for the alternative hypothesis (H\textsubscript{1}) compared to the null (H\textsubscript{0}) and vice versa. All Bayesian paired samples t-tests were directional, as indicated in the \textit{\nameref{prereg_analyses}} section and frequentist equivalents were non-directional (two-tailed). The effect size is represented by Cohen's \textit{d}.}
\end{tablenotes}
\end{table}


\begin{figure} [!htb]
\centering
\includegraphics[width=\linewidth]{figures/Figure4.png}
\captionof{figure}{\textbf{Raincloud plot of the proportion of correct responses on signal trials.} The proportion of correct responses on signal trials (PC\textsubscript{signal}) was relatively greater for no-go foods compared to control foods. The PC\textsubscript{signal} distribution for control foods was heavily skewed and this observation warranted a robustness check for effect estimates, as presented in the \textit{\nameref{robust}} section. \textit{Note.} The `split-half violin' elements in the plot show smoothed and trimmed distributions. Individual data points have been jittered  to some degree due to overfitting, as it can be seen for the cluster of data points for very high proportions of correct responses.} 
\label{fig:signal_accuracy}
\end{figure} 
\newpage

## Findings from exploratory analyses {#exploratory}

### Baseline approach bias scores {#baseline_bias}

Performance in the AAT was inspected further to check if approach bias for foods was present in the final sample and whether error rates differed across conditions. Although the sample means for AAT\textsubscript{pre} bias scores were negative for go foods (*M* = -2.32, *SD* = 58.14), no-go foods (*M* = -4.75, *SD* = 60.58) and filler foods (*M* = -4.48, *SD* = 52.25), individual data points (see Figure \ref{fig:raincloud_bias}) show less dispersion close to zero, suggesting that, on average, neither approach or avoidance bias was captured by the AAT. In line with previous literature [see Table 1 in @becker_approach_2015-1], this hypothesis was directly tested by examining whether baseline bias scores statistically deviated from zero using Bayesian one sample t-tests with the default prior settings for the two-sided alternative hypothesis that the population mean was larger than the test value (0). Equivalent frequentist tests were also conducted.  Overall, conclusive evidence for the absence of baseline approach/avoidance bias was obtained (see Table \ref{tab:baseline}). 
\par
As baseline bias scores calculated from completion times may be 'contaminated' by motor demands in this version of the AAT that requires computer mouse movements and arm flexion/extension, we considered the possibility that motor initiation times may be more sensitive to capturing automatic action tendencies was considered. Movement initiation was registered when participants had moved their mouse cursor since starting a trial (i.e., stimulus onset), including the pixel tolerance for natural movements of the mouse (see \textit{\nameref{aat}}). Therefore, tests were also conducted for baseline bias scores calculated using median initiation times, instead of median completion times. Consistent with the results presented above, there was strong evidence that baseline bias scores did not deviate from zero across training conditions (see Table \ref{tab:baseline}).

\begin{table}[h] 
	\centering
	\caption{Results of Bayesian and frequentist one sample t-tests for baseline approach-avoidance bias scores}
	\label{tab:baseline}
	{
		\begin{tabular}{lrrrrrr}
			\toprule
			 &  &  &  & & \multicolumn{2}{c}{95\% CI for \textit{d}} \\
			\cline{6-7}
			 & \textit{BF}\textsubscript{01}  & \textit{t}(162) & \textit{p} & \textit{d} & Lower & Upper \\
			\cmidrule(r){1-7}
			Completion time: AAT\textsubscript{pre}-go & 10.08 & -0.51& 0.611 & -0.04 & -0.19 & 0.11  \\
			Completion time: AAT\textsubscript{pre}-no-go  & 7.01 & -1.00 & 0.318 & -0.08 & -0.23 & 0.08 \\
			Completion time: AAT\textsubscript{pre}-control & 7.02 & -1.00 & 0.319 & -0.08 & -0.23 & 0.08 \\
			Initiation time: AAT\textsubscript{pre}-go & 10.73 & -0.36 & 0.718 & -0.03 & -0.18 & 0.13  \\
			Initiation time: AAT\textsubscript{pre}-no-go & 10.18 & -0.49 & 0.626 & -0.04 & -0.19 & 0.12 \\
			Initiation time: AAT\textsubscript{pre}-control & 10.46 & -0.43 & 0.669 & -0.03 & -0.19 & 0.12 \\
			\bottomrule
		\end{tabular}
	}
	\begin{tablenotes}[para]
\footnotesize{\textit{Note.} AAT\textsubscript{pre}: Pre-training approach avoidance task bias scores (for go, no-go or control foods)}
\end{tablenotes}
\end{table}

### Sub-group analysis {#subgroup}

In an effort to show that training did not have an effect on AAT outcomes was not due to the absence of baseline approach bias for unhealthy foods, a sub-group analysis for participants with positive baseline bias scores (N=72) was conducted. There was *very strong* evidence for the absence of a main effect of go/no-go training condition on the change in approach-avoidance bias scores [*BF*$_{01}$ = 43.99; *F*(2, 142) = 0.01, *p* = 0.987]. For this sub-group food-choice outcomes were consistent with the results reported in \textit{\nameref{training_outcomes}}. There was *strong* evidence that the probability of choosing a no-go food (*M* = 0.20, *SD* = 0.27) was lower than the probability of choosing a control food (*M* = 0.37, *SD* = 0.33) [\textit{BF}\textsubscript{10} = 13.97; *t*(70)] = -2.96, *p* = 0.004, \textit{p\textsubscript{W}} = 0.004, *d* = -0.35, 95% CI for *d* = -0.59, -0.11]. There was *moderate* evidence for the absence of a general effect of training condition on the change in liking scores from pre-to post-training [*BF*\textsubscript{01} = 8.91; *F*(2, 142) = 0.94, *p* = 0.392]. With regards to the contingency learning manipulation check, there was *very strong* evidence for a greater proportion of correct responses in signal trials with no-go foods compared to control foods [*BF*\textsubscript{10} = 37.80; *t*(71) = 3.33, *p* = 0.001,\textit{p\textsubscript{W}} < .001, *d* = 0.39, 95% CI for *d* = 0.15, 0.63]. However, there was only *anecdotal* evidence that GoRTs were faster for go foods compared to control foods [*BF*\textsubscript{10} = 3.52; *t*(71)) = -2.38, *p* = 0.020, *d* = -0.28, 95% CI for *d* = -0.52, -0.04].

### Accuracy in the approach-avoidance task {#accuracy_aat}

\par 
Although reaction times are the primary measure of interest for studies that utilise the AAT, an exploratory examination of error rates is also reported. At baseline, average error rates were not increased for trials where participants were required to avoid an appetitive food and complete a push action (*M* = 0.136, *SD* = 0.070) relative to trials where an approach (pull) action was completed (*M* = 0.143, *SD* = 0.066) [\textit{BF}\textsubscript{01} = 26.49; \textit{t}(162) = 1.42, \textit{p}= 0.159, \textit{d} = 0.11, 95% CI for \textit{d} = -0.04, 0.26]. However, after training participants had on average more errors in approach trials (*M* = 0.124, *SD* = 0.074) compared to avoid trials (*M* = 0.105, *SD* = 0.062) [\textit{BF}\textsubscript{10} = 90.98, \textit{t}(162) = 3.64, \textit{p} < .001, \textit{p\textsubscript{W}} < .001, \textit{d} = 0.29, 95% CI for \textit{d} = 0.13, 0.44]. It is possible that training had a 'hidden' effect on accuracy, for example it was more difficult to approach no-go foods compared to go and/or control foods due to a learned association between response inhibition and these food stimuli. Difference scores were calculated from the mean error rates post-training (pull - push) to check whether this increase in error rates was general or specific to training conditions. There was very strong evidence for the absence of a general effect of training condition on differences in mean error rates between approach and avoid trials [H3; *BF*\textsubscript{01} = 37.16; *F*(2, 324) = 0.17, *p* = 0.844].  RT differences between approach and avoid trials were also inspected and there was *strong* evidence for slower RTs on pull compared to push actions  after training [*BF*\textsubscript{10} = 11.32; *t*(162) = 2.95, *p* = 0.004, \textit{p\textsubscript{W}} = 0.002, *d* = 0.23, 95% CI for *d* = 0.08, 0.39]. Together these results may indicate fatigue effects associated with bio-mechanical costs (e.g., arm flexion muscle group activation).

\begin{figure} [!htb]
\centering
\includegraphics[width=\linewidth]{figures/Figure5.png}
\captionof{figure}{\textbf{Scatterplots for the test-retest reliability of approach-avoidance bias scores.} For the pre-registered analysis of training outcomes on automatic action tendencies [H1], approach-avoidance bias scores ($\Delta$AAT) were calculated based on median reaction times for correct pull and push responses from pre-to post-training (AAT\textsubscript{post} - AAT\textsubscript{pre}). These reaction times refer to the time participants took to complete an action (i.e., completion time). The test-retest reliability for the calculated scores is poor (Pearson’s \textit{r} coefficient = 0.41; see \textit{\nameref{reliability}} for detailed results). When bias scores are computed using the time when participants initiated a movement since stimulus onset on a correct trial (i..e, initiation times), the test-retest reliability was slightly improved (\textit{r} = 0.53) and less dispersion was observed for $\Delta$AAT across participants.} 
\label{fig:test_retest}
\end{figure} 

### Reliability of calculated bias scores {#reliability}

Given the absence of evidence for baseline approach-avoidance bias scores deviating from zero and the variability in their distributions (see Figure 2), their test-retest reliability was explored. Considering that the the interval between pre- and post-training AAT blocks was very short and there could be added variability (i.e. noise) due to the GNG intervention, a test-retest reliability (or stability)  coefficient *r* within the range of 0.6-0.7 would be considered adequate in this context. Test-retest reliability was assessed via correlation pairs for AAT bias scores at baseline (AAT\textsubscript{pre}) and after training (AAT\textsubscript{post}), as shown in Figure \ref{fig:test_retest}. Consistent with previous analyses (see \textit{\nameref{baseline_bias}}), test-retest reliability was examined for both completion time and initiation time AAT bias scores. Bayesian correlation pairs with the default prior [stretched beta with $\gamma$=1; @wagenmakers_how_2016-1] were used for these analyses. As expected, there was *extreme* evidence for a positive linear relationship between completion time bias scores for pre- and post- training blocks, but the correlation coefficient (Pearson's rho) was only 0.41, indicating that the test-retest reliability of AAT bias scores based on completion times was poor [log(\textit{BF}\textsubscript{10}) = 12.95, *p* < .001, 95% CI for *r* = 0.30, 1]. As discussed earlier, bias scores based on median completion times could be affected by noise in motor times and scores based on median initiation times would better reflect underlying cognitive processes, such as *automatic* action tendencies. The test-retest reliability for bias scores based on initiation times however was slightly better compared to completion time bias scores with a stability coefficient of 0.53 [log(\textit{BF}\textsubscript{10}) = 24.34, *p* < .001, 95% CI for *r* = 0.43, 1]. 

### Devaluation trends across training conditions {#devaluation_trends}

As explained in Figure \ref{fig:raincloud_liking}, there was a general trend of devaluation in the data for all training conditions from pre- to post-training. These observed differencesw were tested directly and there was conclusive evidence that within each training condition cell, there was a negative change in mean liking ratings from pre- to post-training. The control (filler) foods should have been unaffected in terms of affective evaluation changes, but participants rated filler foods more negatively after training (*M* = 68.55, *SD* = 15.81) relative to baseline (*M* = 71.16, *SD* = 14.80) [*BF*\textsubscript{10} = 156.54, *t*(162) = 3.80, *p* < .001, \textit{p\textsubscript{W}} = 0.001, *d* = 0.30, 95% CI for *d* = 0.14, 0.45]. Contrary to predictions about the increase in positive evaluations for go foods (relative to control), within that condition cell the evaluations of go foods were less positive after training (*M* = 67.42, *SD* = 16.85) compared to before (*M* = 70.29, *SD* = 16.80) [*BF*\textsubscript{10} = 84.52, *t*(162) = 3.62, *p* < .001, \textit{p\textsubscript{W}} < .001, *d* = 0.28, 95% CI for *d* = 0.13, 0.44]. The effect was greater for no-go foods, but this is the only data trend that was theoretically consistent with effects of training. Participants provided less positive ratings for no-go foods after training (*M* = 68.83, *SD* = 16.81) compared to before (*M* = 72.99, *SD* = 15.38) [*BF*\textsubscript{10} = 211398.68, *t*(162) = 5.58, *p* < .001, \textit{p\textsubscript{W}} < .001, *d* = 0.44, 95% CI for *d* = 0.28, 0.60]. 

\begin{figure} [!hb]
\centering
\includegraphics[width=\linewidth]{figures/Figure6.png}
\captionof{figure}{\textbf{Raincloud plot of the mean liking ratings pre- and post- training across training conditions.} This visualisation of the mean liking ratings from all participants revealed that the distributions are more skewed than expected, towards the least liked range of the visual analogue scale (VAS). Taste (liking) ratings were registered on a VAS ranging from 0 to 100 (i.e., 50=neutral). Although there appears to be a small difference between the change in liking for no-go foods compared to the control, the trends presented in this plot were inspected further to establish whether observed effects were robust (see \textit{\nameref{robust}}). Also, there appears to be a general trend of devaluation across training conditions and this was statistically supported (see \textit{\nameref{devaluation_trends}}). \textit{Note.} The `split-half violin' elements in the plot show smoothed and trimmed distributions and boxplot vertical lines represent the range, excluding outliers based on the Interquantile Range. Square boxes have been added to depict the sample means, connected with dashed lines across training conditions.} 
\label{fig:raincloud_liking}
\end{figure} 

### General linear model of food choice data  {#glm}

\par
As shown in Figure 4 and as expected for counts data, food choice probabilities were not normally distributed and the inferences based on paired t-tests would need to be validated further. Choice count data from the impulsive food choice task were modelled using a general linear model (GLM) in R. The error term of the model was specified with a Poisson distribution and the link function log-transformed the linear predictor within the model (i.e., logarithms of fitted means). The only predictor in this model was the training condition (i.e.., go, no-go, or filler foods). Diagnostic plots showed mild violations of the assumptions of homoskedasticity and normality of residuals and thus robust standard errors for the parameter estimates were computed [@cameron_microeconometrics_2009]. An overdispersion test [@cameron_microeconometrics_2005; @kleiber_applied_2008] showed that true dispersion was not greater than 1 and the goodness-of-fit chi-squared test was not statistically significant, indicating that the model had a good fit (Residual variance = 436.15, df = 486, *p* = 0.949). The GLM results are consistent with the pre-registered statistical test results (see Table \ref{tab:prereg}). The model showed that impulsive choice probability for no-go foods was 0.53 times the choice probability for control foods [Estimate (log) = -0.617, Robust SE = 0.119,  *p* < .001, 95% CI = -0.851, -0.383)]. The probability of choosing a go food after training was 1.22 times the probability of choosing a control food [Esimate (log) = 0.197, Robust SE = 0.091, *p* = 0.030, 95% CI = 0.019, 0.374]. 

```{r echo=FALSE, include=FALSE}
yu <- read.csv("yuens.csv")
yu$p <- round(yu$p, 3)
```

\begin{table}[h] 
	\centering
	\caption{Yuen's tests of trimmed mean differences for paired comparisons that violated the normality assumption}
	\label{tab:robust}
	{
		\begin{tabular}{lrrrrrrrr}
			\toprule
			 &  &  &  & \multicolumn{2}{c}{95\% CI} &  &  Comparison to  & Effect size\\
			\cline{5-6}
			 & \textit{t}(98) & \textit{p} & \textit{MD\textsubscript{t}} & Lower & Upper  & \textit{$\xi$} & confirmatory test & interpretation \\
			\cmidrule(r){1-9}
			`r yu$H[1]` & `r yu$t[1]` & `r yu$p[1]` & `r yu$md[1]` & `r yu$ll[1]` & `r yu$ul[1]` & `r yu$xi[1]` & Consistent & None\\
			`r yu$H[2]` & `r yu$t[2]` & `r yu$p[2]` & `r yu$md[2]` & `r yu$ll[2]` & `r yu$ul[2]` & `r yu$xi[2]` & Consistent & Very small\\
			`r yu$H[3]` & `r yu$t[3]` & `r yu$p[3]` & `r yu$md[3]` & `r yu$ll[3]` & `r yu$ul[3]` & `r yu$xi[3]` & Consistent & None \\
			`r yu$H[4]` & `r yu$t[4]` & `r yu$p[4]` & `r yu$md[4]` & `r yu$ll[4]` & `r yu$ul[4]` & `r yu$xi[4]` & Consistent & Small \\
			\bottomrule
		\end{tabular}
	}
	\begin{tablenotes}[para]
\footnotesize{\textit{Note.} The degrees of freedom for the robust \textit{t} statistic are 98 because of trimming at 20\% for both tails of the distribution (i.e., N = 99). `Comparison to confirmatory test' refers to whether or not the results from Yuen's tests were consistent with the pre-registered, confirmatory test results. \textit{MD\textsubscript{t}}: trimmed mean difference; \textit{$\xi$}: explanatory measure of effect size}
\end{tablenotes}
\end{table}

### Robust statistics {#robust}

For certain pre-registered paired comparisons, where the difference scores were found to violate the normality assumption (Shapiro-Wilk test with *p* $\leq$ .005), it was possible that effect size estimates were biased and therefore robust statistics are also reported [@lakens_20_2015]. H2a and H2b have been ommitted as robust analyses have already been implemented above (see \textit{\nameref{glm}}). Yuen's method of comparing trimmed means was applied via the WRS2 package, with the recommended percentage of 20% trimming from both tails of the distribution [@mair_robust_2019; @wilcox_measuring_2011; @yuen_two-sample_1974]. The explanatory measure of effect size, represented by $\xi$ is provided and can be conventionally interpreted as small, medium and large at 0.15, 0.35 and 0.50 [@mair_robust_2019]. The null hypothesis in Yuen's test for paired sample comparisons is that there is no difference between the trimmed means (\textit{$\mu$\textsubscript{t}}\textsubscript{1} = \textit{$\mu$\textsubscript{t}}\textsubscript{2}). The test results are shown in Table \ref{tab:robust} and were consistent with findings from pre-registered confirmatory analyses. The explanatory effect sizes did not deviate in their interpretation from Cohen's *d* values presented in Table \ref{tab:prereg} for frequentists paired-samples t-tests, as the observed effects were small for both H3a and H4a. 


# Discussion  {#discussion}

The primary aim of the study was to investigate whether inhibitory control training (ICT) can have an indirect effect on automatic action tendencies on the premise that the devaluation process that occurs during training may lead to reduced approach bias for foods associated with response inhibition. It was hypothesized that approach bias for unhealthy foods associated with a no-go response during go/no-go training (i.e., response inhibition) would be reduced compared to filler foods that were paired with both go and no-go responses with an equal probability (control). Automatic action tendencies were indirectly measured using a variant of the approach-avoidance task (AAT) that includes a 'zooming' feature for push/pull actions [@neumann_approach_2000] of the computer mouse and requires participants to judge the orientation of the presented picture [@wiers_automatic_2013]. Approach-avoidance bias scores were calculated from AAT blocks before and after training by subtracting median RTs on approach trials (pull action) from median RTs on avoid trials (push action). Positive scores would indicate an approach bias towards unhealthy foods.

## No effects of training on automatic action tendencies
\par
 As a primary outcome measure, the change in bias scores from pre-to post-training was examined across training conditions. The results from the pre-registered analyses showed that ICT did not have an effect on automatic action tendencies, as there was *moderate* evidence that approach bias for no-go foods was not reduced relative to control foods after training (H1a) as well as *strong* evidence that approach bias for go foods was not increased compared to control foods after training (H1b). Although such ICT effects may not have been previously investigated, or published due to selective reporting of significant findings [e.g., see @carbine_quantifying_2019], there is empirical evidence to suggest that food stimuli included in AAT training protocols can be associated with increased avoidance behaviour (or reduced approach) after training [e.g., @dickson_pulling_2016; @schumacher_bias_2016]. A significant change in approach-avoidance bias scores was not observed in another series of experiments [@becker_approach_2015-1], but presence or absence of training effects may also depend on methodological parameters of training and employed controls [see @jones_cognitive_2018 for review], as discussed further below (see \textit{\nameref{methodological_considerations}}). 

## Response inhibition \& impulsive food choices
\par
As a secondary outcome measure, impulsive food choices were assessed via an adapted food choice task [@veling_stop_2013] after training. Participants had ten seconds to choose three food stimuli from all training conditions (go, no-go or control). Pre-registered analyses showed that the probability of choosing a no-go food was lower than the probability of choosing a control food (H2a). Meanwhile, there was no difference between the probability of choosing a go food relative to the probability of choosing a control food (H2b). The conclusion that ICT can have an effect on impulsive food choices is consistent with previous studies that have used both go/no-go and stop-signal task paradigms [@veling_using_2013; @veling_stop_2013], but cannot be directly compared to experiments involving cue-approach training, which involves responding to go items in response to a cue or signal. These studies have found increased food choices for go food items [@schonberg_changing_2014; @veling_training_2017]. Food choices can either be deliberate or impulsive (added time pressure in experimental settings) and hypothetical or consequential, whereby participants are aware that their choices will determine what food they are offered by the experimenter at the end of the study [e.g., see @chen_when_2019]. The present findings should therefore be replicated and extended with different experimental manipulations as well (e.g., speeded binary choice task). 

## Devaluation effects  \& design limitations
\par
Another important training outcome which was also treated as manipulation check for the ICT paradigm was the change in food evaluations from pre-to post-training. According to the BSI theory of stimulus devaluation, as already introduced, successful inhibition of responses on signal trials is facilitated by an underlying devaluation process for appetitive foods, whereby approach bias for these foods is reduced [@veling_what_2017; @veling_when_2008]. Consistent with previous studies where go/no-go training led to robust food devaluation effects [see @chen_how_2016 for a series of pre-registered experiments], it was expected that the change in mean tastiness ratings (i.e., food liking) for no-go foods from pre-to post-training would be reduced compared to the change in ratings for filler foods. Pre-registered analyses showed only *anecdotal* evidence that no-go foods were rated less positively after training compared to filler foods (H3a). Similarly, participants did not show increased liking for go foods relative to the filler foods, from pre-to post-training (H3b). It should be noted that filler foods which were associated with both go and no-go responses (50:50) are not an ideal control for devaluation effects, as @chen_how_2016 correctly point out that effects should be observed for two baselines in order for proper inferences to be made. They compared changes in evaluation for no-go foods compared to changes for go foods as well as changes for untrained food stimuli, which were never included in training. In their design, food stimuli sets were matched in valence before training. However, participants in this study were only presented with a fixed set of unhealthy foods which were considered appetitive (e.g., pizza, cake, crisps) and this was a viable limitation with regards to the examination of devaluation effects. Indeed, there is evidence to suggest that devaluation is observed only when highly appetitive foods are associated with response inhibition [see @chen_how_2016].
\par
Exploratory analyses further showed that while on average no-go foods were rated less positively after training compared to before, there was a general devaluation trend for both go and control foods (see \textit{\nameref{devaluation_trends}}). It is possible that `over-exposure' to food stimuli from all training conditions during the phases of the study (pre-training, training, and post-training) could have had a habituation effect on participants' affective evaluations of any presented foods at the end of the study. It is also unclear whether stimulus-response mappings in the AAT affected GNG manipulations, as for example a correct response on push trials may require response inhibition, whereby an initial approach tendency towards an appetitive food cue is inhibited. This would mean that, at least to a certain extent, all food stimuli were associated with an inhibitory control process. It is therefore recommended that future studies only present outcome measures, such as the AAT, only after training, which can reduce potential habituation effects, but also enhance the experimental design if untrained food stimuli are included as additional controls. This design can also increase the number of observations without the need for possibly problematic data reduction, such as calculating a difference score of the AAT\textsubscript{pre} and AAT\textsubscript{post} bias scores which are also represented by difference scores between median RTs in approach and avoid trials. The absence of devaluation effects specific to no-go foods could not be attributed to ineffective training, as the second manipulation check for contingency learning during the go/no-go task was positive. There was *extreme* evidence that GoRTs on correct no-signal trials were reduced for go foods compared to control foods and that the percentage of correct responses on signal trials were greater for no-go foods relative to control foods. Overall, ICT outcomes for devaluation contradicted prior expectations, while taking into account that limitations of the experimental design may have had a significant impact on observed effects.  

## Methodological considerations for the approach-avoidance task {#methodological_considerations}
\par
There were several findings from exploratory analyses regarding the approach avoidance task that may explain the absence of ICT effects on automatic action tendencies and yielded methodological considerations for future studies.  First, overall baseline bias scores did not statistically deviate from zero (see \textit{\nameref{baseline_bias}}), which suggests that either participants did not have any approach bias for the selected foods or the employed variant of the AAT was not sensitive enough to capture both baseline bias and potential indirect effects of training. Sub-group analyses showed that even when participants had positive bias scores for unhealthy foods, which reflect existing approach bias, there were still no effects of training on automatic action tendencies (see \textit{\nameref{subgroup}}). Consequently, the test-retest reliability of the calculated bias scores for pre-and post-training AAT blocks was inspected and the stability coefficients showed poor reliability (see \textit{\nameref{reliability}}). Test-retest reliability was slightly improved when bias scores were calculated using initiation times, instead of completion times, which may be due to individual differences in action-associated motor demands (i.e., biceps and triceps muscle activation for pushing/pulling the computer mouse). We suggest that initiation time represents a more reliable measure for the calculation of AAT bias scores [e.g., see @seibt_prepared_2007-1]. It is also unclear whether any time of response latency measure derived from sensorimotor tasks, such as the AAT variant employed in this study, can be indicative of approach-avoidance bias, since the role of arm movements in these motivational processes has recently been questioned for the controversial replicability of findings and the importance of whole-body movements in real-world approach-avoidance behaviours [@rougier_new_2018]. An element of the AAT variant that could have affected the reliability of the bias scores was the use of a computer mouse instead of a joystick, as in the seminal version of this paradigm [@rinck_approach_2007; @wiers_relatively_2009]. However, any motor demand differences between the joystick and computer mouse would not affect the initiation times, which were also found to have questionable test-retest reliability. The variability in methodology for the measurement of motivational bias should be taken into account, as different parameters might need to be examined further when the AAT is applied in the food domain [e.g., explicit vs implicit task instructions; see @phaf_approach_2014 for meta-analysis]. In a recent study, [@lender_measurement_2018] found that the irrelevant-feature of the AAT did not lead to robust approach-bias, compared to relevant-feature variants which require participants to pay attention to the content of the stimuli.
\par
Certainly, there are methodological issues with the application of the AAT as an indirect measure of approach bias in ICT studies that have strict comparisons for outcomes based only food stimuli. For example, one approach for making inferences based on AAT scores is to calculate a *relative* bias based on the push-pull median RT differences from one category (e.g., alcohol) versus another (e.g., non-alcohol), as reported in previous literature [@sharbanee_approach-alcohol_2014; @van_deursen_web-based_2013]. However, in the present study design the AAT included only sweet and savoury unhealthy foods and bias scores were based on the differences between push and pull actions alone. The control for relative bias scores should be specific to the question of interest, such as healthy foods, if approach bias and healthiness is to be examined, or non-food stimuli if a general food approach bias is to be inferred. In any case, the control stimuli need to be matched in liking (i.e., hedonic value) so that any resulting bias scores reflect differences in motivational bias and not affective/hedonic bias [@kemps_approach_2015]. Setting aside the methodological utility of the AAT in this context, it is possible that go/no-go training with the specific parameters applied in this study, did not have an effect on automatic action tendencies, but this research question could be addressed in future empirical studies that utilise alternative measures of motivational bias, such as the relevant stimulus-response compatibility task [e.g., see @field_alcohol_2011].

## Concluding remarks \& future directions
\par
As thorough search of the literature did not indicate that the AAT has previously been employed as an outcome measure in ICT studies utilising the go/no-go training paradigm, twe believe that the null findings presented here can shed light into methodological and theoretical issues to be explored further. From a theoretical standpoint, there could be a link between stimulus devaluation during ICT training and automatic action tendencies. If a tendency to approach an appetitive food is reduced during go/no-go training in order for response inhibition to be successful, the approach bias towards food stimuli associated with signal trials could be indirectly affected by this process. The absence of devaluation effects in this study could therefore explain the finding that ICT did not have any influence on automatic action tendencies. Nevertheless, there are several methodological limitations regarding the application of the AAT as an indirect measure of motivational bias that need to be addressed before drawing any conclusions and these would need to be addressed in future studies. On a final note, it is worth mentioning that there are various methodological parameters and protocols that can be implemented for both inhibitory control training and measurement of approach-avoidance bias and this can pose an important replicability issue.  It is recommended that novel findings, irrespective of statistical significance, are replicated and/or extended in a rigorous and reproducible manner, in an effort to also reduce selective reporting and publication bias in this line of research [e.g., see @aulbach_implicit_2019; @carbine_quantifying_2019]. 

```{r render_appendix, include=FALSE}
render_appendix("appendix.Rmd")
```

\include{Appendix}

# References
```{r create_references}
r_refs(file = "references.bib")
```




\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = "refs"></div>
\endgroup 

\textbf{\hl{Notes for review}}
- Weird spaces between some sections: This is a LaTex issue and will be fixed in the RMarkdown file later. 
- Please ignore any typos or minor formatting errors at this stage
- Some references need to be fixed - Journal abbreviations and middle names will be manually fixed later on
- For thesis purposes I have removed all 'we' and 'our' phrases, but for the paper we can re-edit some parts
- Thesis vs manuscript: this is very long for journal submission, so feel free to make suggestions for any content that may need to go into either Appendix (in paper) or Supplementary Material
- *Important*: there are too many participant exclusions for AAT error rates and I am wondering whether the 25% threshold was too strict - I don't know how ethical it is to throw all this data away.. I think maybe at a later stage we can include analyses in supplementary with a less conservative threshold - e.g. 35%

