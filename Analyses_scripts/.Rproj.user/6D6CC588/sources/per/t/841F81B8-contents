---
title: "Pre-processing pipeline for confirmatory analyses"
author: "Loukia Tzavella"
date: "15/06/2019"
output: html_document
---

### R environment and data files 

* Install and/or load required R packages 

```{r warning=FALSE, message=FALSE}
required.packages <- c("data.table", "plyr", "dplyr", "here")
new.packages <- required.packages[!(required.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)>0) {install.packages(required.packages)}

require(data.table)
require(plyr)
require(dplyr)
require(here)
```

* Make a list with raw data files

> Raw data can be downloaded directly from the OSF page (https://osf.io/eu6xj/) and should be saved in the 'raw_data' folder. 
> The 'summary_processed.csv' file should be added to the R project directory (not a specific folder)

```{r}
files <- list.files(here("raw_data/"), all.files = TRUE, full.names = FALSE, no.. = TRUE, pattern = "\\.csv$")

data <- lapply(here("raw_data/", files), function(x) {fread(x)})
data <- lapply(data, function(x) as.data.frame(x))

#Assign names to the list elements (subject IDs)

IDs <- lapply(data, function(x) head(x$script.subjectid, n=1))
IDs <- lapply(IDs, function(x) as.character(x))
names(data) <- IDs
```

* Load R script with user-defined functions 
```{r}
source("Functions_1.R")
```

### Correct raw data output from the AAT

* We run the experiment using the latest version of Inquisit Web at the time and preliminary analyses revealed that there was not much variability in completion RTs of the AAT. Upon closer data inspection, we discovered that the temporal resolution in which the script was programmed to record RTs was incorrect. We have copied an official description of the bug below. 

> "Inquisit 5.0.10 and earlier had a bug which caused Inquisit to unnecessarily wait for up to 1 full vertical refresh cycle while running trials that present stimuli. For a monitor running at 60hz, this could introduce up to 16.7ms of lag between consecutive trials. The bug was fixed in 5.0.11."

* This caused a lot of duplicate RTs and low granularity, which would be especially problematic for capturing performance differences in tasks such as the AAT which require averaging and calculation of difference scores, which are often very small in magnitude). For this reason, we use linear interpolation for every trial to increase the number of samples for the mouse coordinates and reaction time values to 100. Therefore, if a coordinate was reached earlier than shown we could get the closest RT during that timepoint. 

* The script also had a lag of mouse coordinates by one row and therefore the last coordinate which met the criteria for the end of a zooming trial appears on one trial event / row later - namely *zoom_in_end_l/p* and *zoom_out_end_l/p*.

* Since RTs and coordinates are corrected, we will check accuracy again and not use the existing valuesin the raw data (e.g., values.aat_correct), apart from values.initial_direction, which shouldn't be affected as it is registered during the beginning of a mouse movement.

* This means that performance-related exclusions are applied after the correction of the AAT data. 

#### Subset AAT data and rename/create variables of interest

```{r}
#Copy initiation time to a new column which contains first RT (init time) and rest of sampled RTs - 'rt'
data <- lapply(data, transform, rt = ifelse(trialcode=="avoid_1"|trialcode=="avoid_2"|trialcode=="approach_1"|trialcode=="approach_2",
                                             values.init_time, values.aat_rt))

#Get unique codes for conditions (one column)
data <- lapply(data, transform, condition = ifelse(values.aat_block=="pre" & values.aat_trial_cat=="fill" & values.aat_trial_type=="approach", "pre_pull_filler",
                                            ifelse(values.aat_block=="pre" & values.aat_trial_cat=="fill" & values.aat_trial_type=="avoid", "pre_push_filler",
                                            ifelse(values.aat_block=="pre" & values.aat_trial_cat=="go" & values.aat_trial_type=="approach", "pre_pull_go",
                                            ifelse(values.aat_block=="pre" & values.aat_trial_cat=="go" & values.aat_trial_type=="avoid", "pre_push_go",
                                            ifelse(values.aat_block=="pre" & values.aat_trial_cat=="nogo" & values.aat_trial_type=="approach", "pre_pull_nogo",
                                            ifelse(values.aat_block=="pre" & values.aat_trial_cat=="nogo" & values.aat_trial_type=="avoid", "pre_push_nogo",
                                                   
                                            ifelse(values.aat_block=="post" & values.aat_trial_cat=="fill" & values.aat_trial_type=="approach", "post_pull_filler",
                                            ifelse(values.aat_block=="post" & values.aat_trial_cat=="fill" & values.aat_trial_type=="avoid", "post_push_filler",
                                            ifelse(values.aat_block=="post" & values.aat_trial_cat=="go" & values.aat_trial_type=="approach", "post_pull_go",
                                            ifelse(values.aat_block=="post" & values.aat_trial_cat=="go" & values.aat_trial_type=="avoid", "post_push_go",
                                            ifelse(values.aat_block=="post" & values.aat_trial_cat=="nogo" & values.aat_trial_type=="approach", "post_pull_nogo",
                                            ifelse(values.aat_block=="post" & values.aat_trial_cat=="nogo" & values.aat_trial_type=="avoid", "post_push_nogo",       
                                                   "nan")))))))))))))

#Subset AAT data

AAT_data <- lapply(data, subset, select=c("script.subjectid", "blockcode", "trialcode", "rt", "values.x", "values.y", "condition", "values.aat_correct",
                                          "values.init_correct", "values.final_correct", "values.init_time", "display.canvasheight",           
                                          "display.canvaswidth","values.initial_response", "values.final_response"),
                                          (blockcode=="pre_aat"|blockcode=="post_aat") & condition!="nan" & trialcode!="aat_break" & trialcode!="clear_screen"
                                          & trialcode!="pre_aat" & trialcode!="post_aat")

#Create unique trial numbers for both pre- and post-AAT blocks
AAT_data <- lapply(AAT_data, transform, trial = ifelse(trialcode=="start_aat", 1, 0))
AAT_data <- lapply(AAT_data, transform, trial = ave(trial, FUN=cumsum))
```

* Linear interpolation of mouse coordinates and RT samples

```{r}
#Correct lagged coordinates 
AAT_data <- lapply(AAT_data, transform, mousey = lead(values.y, 1))
AAT_data <- lapply(AAT_data, transform, mousex = lead(values.x, 1))

#RT values on start_aat trial events should be 0. This step is important for the interpolation, if this is not set to 0, it won't work properly.
AAT_data <- lapply(AAT_data, transform, rt = ifelse(trialcode=="start_aat", 0, rt))

#Extract relevant data from the lists and replicate for each trial 100 times to bind with interpolated data 
#Interpolation will not include 'iti_aat' trials as these affect the results and are not part of mouse trajectories

#Please note that this may take a few minutes

AAT_inter <- lapply(AAT_data, function(i) cbind(ddply(subset(i, trialcode!="iti_aat"), .(trial, condition), interp), 
                      ddply(i, .(trial), function(x) cbind(repr(x$values.init_correct[x$trialcode=="iti_aat"], 100), 
                                                  repr(x$values.final_correct[x$trialcode=="iti_aat"], 100),
                                                  repr(x$values.aat_correct[x$trialcode=="iti_aat"], 100),
                                                  repr(x$display.canvasheight[1], 100),
                                                  repr(x$display.canvaswidth[1], 100),
                                                  repr(x$values.init_time[x$trialcode=="iti_aat"], 100),
                                                  repr(x$values.initial_response[x$trialcode=="iti_aat"], 100),
                                                  repr(x$values.final_response[x$trialcode=="iti_aat"], 100),
                                                  repr(x$script.subjectid[1], 100)))))



#Remove trial number which was added again
AAT_inter <- lapply(AAT_inter, subset, select=c(1:5, 7:15))

#Rename new columns
new_colnames <- c("trial", "condition", "rt", "mousey", "mousex", "init_correct", "final_correct", "aat_correct", "height", "width", "init_time", "init_response", "final_response", "id")

AAT_inter <- lapply(AAT_inter, setnames, new_colnames)
```

* Register accuracy related measures for AAT data

```{r}
#Record then the margin top/low is hit including the pixel tolerance 0.0125% of display canvas height, 
#as included in the Inquisit script for the study

AAT_inter <- lapply(AAT_inter, transform, hit = ifelse(mousey<= (0.0125 * as.numeric(as.character(height[1]))), "min_hit", ifelse(mousey >=(as.numeric(as.character(height[1]))-(0.0125 * as.numeric(as.character(height[1])))), "max_hit", "no_hit")))

#Create a variable for sample number
AAT_inter <- lapply(AAT_inter, transform, number = rep(1:100, n=216))

#Create a variable for total rt when either the bottom or the top of the screen has been reached 
AAT_inter <- lapply(AAT_inter, transform, total_rt = ifelse(hit=="max_hit"|hit=="min_hit", rt, 0))

#Number the samples in which this condition is met so that we can take the first time a margin is hit
AAT_inter <- lapply(AAT_inter, transform, sample = ifelse(total_rt >0, 1, 0))
AAT_inter <- lapply(AAT_inter, transform, sample = ave(sample, cumsum(sample==0), FUN=cumsum)) 

#Add a variable for capturing different types of incorrect responses
AAT_inter <- lapply(AAT_inter, transform, action =  ifelse(condition=="pre_pull_go"|condition=="pre_pull_nogo"|
                                                           condition=="pre_pull_filler"|condition=="post_pull_nogo"|
                                                           condition=="post_pull_go"|condition=="post_pull_filler", "pull", "push"))

AAT_inter <- lapply(AAT_inter, transform, response_change = ifelse(action=="pull" & init_response=="push" & final_response=="push", "inc_avoid",
                                                            ifelse(action=="pull" & init_response=="push" & final_response=="pull", "init_avoid",
                                                            ifelse(action=="push" & init_response=="pull" & final_response=="pull", "inc_approach",
                                                            ifelse(action=="push" & init_response=="pull" & final_response=="push", "init_approach",
                                                            ifelse(action=="pull" & init_response=="pull" & final_response=="pull", "cor_approach",
                                                            ifelse(action=="push" & init_response=="push" & final_response=="push", "cor_avoid", 
                                                                   "other")))))))
#Register accuracy
AAT_inter <- lapply(AAT_inter, transform, accuracy = ifelse(init_correct==1 & final_correct==1 & sample>=1, 1, 0))

#Subset data for descriptive statistics- one row per trial
#We either select the last sample (100) when accuracy is 0 or the first sample of a registered RT
AAT_acc <- lapply(AAT_inter, subset, (number==100 & accuracy==0) | (sample==1 & accuracy==1))

AAT_acc <- lapply(AAT_acc, transform, init_time = as.numeric(as.character(init_time)))
AAT_acc <- lapply(AAT_acc, transform, motor_time = total_rt - init_time)

AAT_acc <- lapply(AAT_acc, transform, condition = as.factor(condition))
```

### AAT outcomes for data exclusions & pre-registered analyses

```{r}
# Create subsetfor correct responses only to measure RT outcomes
AAT_RTs <- lapply(AAT_acc, subset, accuracy==1)

#Recode accuracy values into 0s and 1s to get mean error rates
AAT_ERs <- lapply(AAT_acc, transform, accuracy = as.integer(ifelse(accuracy==1, "0", "1")))


AAT_RTs <- ldply(AAT_RTs, fun_AAT_RTs)
AAT_ERs <- ldply(AAT_ERs, fun_AAT_ERs)

AAT_sum <- cbind(AAT_RTs, AAT_ERs[2:19])

#Bias score calculated as (MedianRTpush - MedianRTpull) for pre- and post- training and the a Delta AAT bias score is obtained

AAT_sum$Pre_Go_bias = (AAT_sum$Pre.Push.Go.RT - AAT_sum$Pre.Pull.Go.RT) 
AAT_sum$Pre_NoGo_bias = (AAT_sum$Pre.Push.NoGo.RT - AAT_sum$Pre.Pull.NoGo.RT) 
AAT_sum$Pre_Filler_bias = (AAT_sum$Pre.Push.Filler.RT - AAT_sum$Pre.Pull.Filler.RT)

AAT_sum$Post_Go_bias = (AAT_sum$Post.Push.Go.RT - AAT_sum$Post.Pull.Go.RT)
AAT_sum$Post_NoGo_bias = (AAT_sum$Post.Push.NoGo.RT - AAT_sum$Post.Pull.NoGo.RT)
AAT_sum$Post_Filler_bias = (AAT_sum$Post.Push.Filler.RT - AAT_sum$Post.Pull.Filler.RT)

AAT_sum$D_Go = (AAT_sum$Post_Go_bias) - (AAT_sum$Pre_Go_bias)
AAT_sum$D_NoGo = (AAT_sum$Post_NoGo_bias) - (AAT_sum$Pre_NoGo_bias)
AAT_sum$D_Filler = (AAT_sum$Post_Filler_bias) - (AAT_sum$Pre_Filler_bias)
```

### GNG data - outcomes for pre-registered analyses

```{r}
#Select training (GNG) trials that include accuraacy and RT outcomes

gng <- lapply(data, subset, blockcode=="gng" & trialcode!="break" & trialcode!="clear_screen")

# Create subset of correct responses only for RT outcomes

gng_rt <-lapply(gng, subset, values.gng_correct==1)

#Recode accuracy values into 0s and 1s 
#Coding is reversed to get the proportion of error rates (PE); i.e., 1=incorrect; 0=correct

gng_pe <- lapply(gng, transform, accuracy = as.integer(ifelse(values.gng_correct==1, "0", "1")))

#Apply functions and get dataframes with RT and PE outcomes

gng_RTs <- ldply(gng_rt, fun_gng_RTs)
gng_PEs <- ldply(gng_pe, fun_gng_PEs)

#Change proportion of error rates (PE) into proportion of correct responses (PC) and bind outcomes together into one dataframe

gng_PEs$FillerGo.PC = 1-gng_PEs$FillerGo.PE
gng_PEs$FillerNoGo.PC = 1-gng_PEs$FillerNoGo.PE
gng_PEs$Go.PC = 1-gng_PEs$Go.PE
gng_PEs$NoGo.PC = 1-gng_PEs$NoGo.PE

GNG_sum <- cbind(gng_RTs, gng_PEs[2:9])
```

### Data exclusions

```{r}
# Percentage of errors in AAT (either pre or post) > 25%
excl1 <- unique(AAT_sum$.id[AAT_sum$Pre.ER>0.25 |  AAT_sum$Post.ER >0.25])

# Percentage of correct responses in no-signal trials <85% (cf. Adams et al. 2016)
excl2 <- unique(GNG_sum$.id[GNG_sum$Go.PC < 0.85])

# Mean GoRT > 3 SDs from the group mean. Note that group mean applies to all data before any other exclusions have been applied

GNG_sum$goRT_rm <- ifelse(GNG_sum$Go.RT > (mean(GNG_sum$Go.RT) + (3 * (sd(GNG_sum$Go.RT)))), "1", "0")
excl3 <- unique(GNG_sum$.id[GNG_sum$goRT_rm==1])

# Percentage of errors on signal trials > 3 SDs from the group mean 

GNG_sum$PE_rm <- ifelse(GNG_sum$NoGo.PE > (mean(GNG_sum$NoGo.PE) + (3 * (sd(GNG_sum$NoGo.PE)))), "1", "0")
excl4 <- unique(GNG_sum$.id[GNG_sum$PE_rm==1])

#We inspected the summary data output from Inquisit for the exclusion of participants that may have provided a food rating of 50 (i.e. neutral)
#systematically, that is, for 14 or more trials either pre- or post- training, but there were no participants meeting this exclusion

# Store eligible IDs and apply criteria to the list of data files
inclIDs <- as.integer(IDs)

inclIDs <- inclIDs[!inclIDs %in% excl1]
inclIDs <- inclIDs[!inclIDs %in% excl2]
inclIDs <- inclIDs[!inclIDs %in% excl3]
inclIDs <- inclIDs[!inclIDs %in% excl4]

inclIDs2 <- as.integer(IDs)
inclIDs2 <- inclIDs2[!inclIDs2 %in% excl2]
inclIDs2 <- inclIDs2[!inclIDs2 %in% excl3]
inclIDs2 <- inclIDs2[!inclIDs2 %in% excl4]

#Keep a copy of AAT data
AAT_copy <- AAT_inter
AAT_sum_copy <- AAT_sum

#this dataset includes all AAT descriptives but the AAT accuracy criterion has not been applied
#we will use this for exploratory analyses
AAT_copy <- AAT_copy[sapply(AAT_copy, function(x) any(x$id %in% inclIDs2))]

AAT_sum_copy <- subset(AAT_sum_copy, .id %in% inclIDs2)

AAT_excl <- subset(AAT_sum_copy, .id %in% excl1)
write.csv(AAT_excl, file=here("csvs", "AAT_excl.csv"), row.names = FALSE)

#Remove from all relevant datasets
data <- data[sapply(data, function(x) any(x$script.subjectid %in% inclIDs))]

AAT_inter <- AAT_inter[sapply(AAT_inter, function(x) any(x$id %in% inclIDs))]
AAT_data <- AAT_data[sapply(AAT_data, function(x) any(x$script.subjectid %in% inclIDs))]
AAT_acc <- AAT_acc[sapply(AAT_acc, function(x) any(x$id %in% inclIDs))]

GNG_sum <- subset(GNG_sum,.id %in% inclIDs)
AAT_sum <- subset(AAT_sum,.id %in% inclIDs)
```

### Export files for JASP analyses
```{r}
write.csv(AAT_sum, file=here("csvs", "AAT_sum.csv"), row.names = FALSE)
write.csv(GNG_sum, file=here("csvs", "GNG_sum.csv"), row.names = FALSE)

write.csv(AAT_sum_copy, file=here("csvs", "AAT_sum_incl.csv"), row.names = FALSE)
```

### Rating data - outcomes for pre-registered analyses

* Create summary file for rating data
```{r}
ratings <- lapply(data, subset, blockcode=="pre_ratings" | blockcode=="post_ratings")
ratings <-lapply(ratings, subset, trialcode!="clear_screen" & trialcode!="ratings_instruct")

ratings<- lapply(ratings, transform, food_category= ifelse(trialcode=="food1_food_rating", "go_savoury",
                                                    ifelse(trialcode=="food2_food_rating", "go_sweet",
                                                    ifelse(trialcode=="food3_food_rating", "nogo_savoury",
                                                    ifelse(trialcode=="food4_food_rating", "nogo_sweet",
                                                    ifelse(trialcode=="food5_food_rating", "filler_savoury", "filler_sweet"))))))
mean_ratings <- ldply(ratings, fun_ratings)

mean_ratings$DLiking_Go = mean_ratings$Post.Liking.Go - mean_ratings$Pre.Liking.Go
mean_ratings$DLiking_Nogo = mean_ratings$Post.Liking.Nogo - mean_ratings$Pre.Liking.Nogo
mean_ratings$DLiking_Filler = mean_ratings$Post.Liking.Filler - mean_ratings$Pre.Liking.Filler

write.csv(mean_ratings, file=here("csvs", "Ratings_sum.csv"), row.names = FALSE)

#exclude_neg_ratings <- subset(mean_ratings, Pre.Liking.Go >=60 & Pre.Liking.Nogo >=60 & Pre.Liking.Filler >=60 )

#write.csv(exclude_neg_ratings, file=here("csvs", "pos_sum.csv"), row.names = FALSE)


ratings_grand <- ldply(ratings, function(x) grand_mean = mean(x$values.rating[x$blockcode=="pre_ratings"]))

#all_data <- cbind(all_data, ratings_grand)
```

### Food choice data - outcomes for pre-registered analyses

```{r}
#'Normalise' food choices according to the total number of responses per participant (i.e., proportion)

sum <- read.csv(file=here("summary_processed.csv"))

levels(sum$values.selected_1) <- c("None","Filler","Filler","Go","Go","Nogo","Nogo")
levels(sum$values.selected_2) <- c("None","Filler","Filler","Go","Go","Nogo","Nogo")
levels(sum$values.selected_3) <- c("None","Filler","Filler","Go","Go","Nogo","Nogo")

sum$Filler=0
sum$Filler <- ifelse(sum$values.selected_1=="Filler", sum$Filler+1, sum$Filler)
sum$Filler <- ifelse(sum$values.selected_2=="Filler", sum$Filler+1, sum$Filler)
sum$Filler <- ifelse(sum$values.selected_3=="Filler", sum$Filler+1, sum$Filler)

sum$Go=0
sum$Go <- ifelse(sum$values.selected_1=="Go", sum$Go+1, sum$Go)
sum$Go <- ifelse(sum$values.selected_2=="Go", sum$Go+1, sum$Go)
sum$Go <- ifelse(sum$values.selected_3=="Go", sum$Go+1, sum$Go)

sum$Nogo=0
sum$Nogo <- ifelse(sum$values.selected_1=="Nogo", sum$Nogo+1, sum$Nogo)
sum$Nogo <- ifelse(sum$values.selected_2=="Nogo", sum$Nogo+1, sum$Nogo)
sum$Nogo <- ifelse(sum$values.selected_3=="Nogo", sum$Nogo+1, sum$Nogo)

sum$Total = sum$Filler+sum$Go+sum$Nogo

sum$P_Filler = sum$Filler / sum$Total
sum$P_Go = sum$Go / sum$Total
sum$P_Nogo = sum$Nogo / sum$Total

#Export summary dataframe with added rating and food choice outcomes
write.csv(sum, file=here("csvs", "Choice_sum.csv"), row.names = FALSE)
```

### Create a csv with all main variables of interest

```{r}
#We arrange all subject IDs in a descending order to bind data together
sum <- sum %>% arrange(desc(script.subjectid))
AAT_sum$.id <- as.integer(AAT_sum$.id)
AAT_sum <- AAT_sum %>% arrange(desc(.id))

GNG_sum$.id <- as.integer(GNG_sum$.id)
GNG_sum <- GNG_sum %>% arrange(desc(.id))

mean_ratings$.id <- as.integer(mean_ratings$.id)
mean_ratings <- mean_ratings %>% arrange(desc(.id))

#Bind columns of interest from choice, AAT, GNG and rating data descriptives
all_data <- cbind(sum, AAT_sum[c(14:17, 30:44)], GNG_sum[2:11], mean_ratings[2:10])

all_data$Pre_Bias = all_data$Pre.Push.RT - all_data$Pre.Pull.RT
all_data$Post_Bias = all_data$Post.Push.RT - all_data$Pre.Pull.RT

all_data$D_Bias <- all_data$Post_Bias - all_data$Pre_Bias
#Export csv file
write.csv(all_data, file=here("csvs", "all_data.csv"), row.names = FALSE)
```
